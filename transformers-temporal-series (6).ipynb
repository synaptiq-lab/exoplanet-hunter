{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:26:59.409102Z",
     "iopub.status.busy": "2025-10-04T23:26:59.408403Z",
     "iopub.status.idle": "2025-10-04T23:27:18.026044Z",
     "shell.execute_reply": "2025-10-04T23:27:18.025146Z",
     "shell.execute_reply.started": "2025-10-04T23:26:59.409080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-04T23:27:18.028206Z",
     "iopub.status.busy": "2025-10-04T23:27:18.027898Z",
     "iopub.status.idle": "2025-10-04T23:27:22.482322Z",
     "shell.execute_reply": "2025-10-04T23:27:22.481510Z",
     "shell.execute_reply.started": "2025-10-04T23:27:18.028173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import pandas as pd\n",
    "import pandas as pd, numpy as np, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement & vues multi-résolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération de la donnée / Filtrage\n",
    "\n",
    "Avant d’appliquer le pipeline de prétraitement (dé-trending spline/GP, sigma-clipping 5σ, normalisation médiane / IQR, uniformisation de cadence), il faut savoir où sont le temps, le flux, et les flags dans le CSV. \n",
    "\n",
    "Comment faire ?\n",
    "\n",
    "Création d'une pipeline générique. Nous allons créer un dictionnaire pour rendre la recherche insensible à la casse (ex : \"time\"->\"TIME\").\n",
    "Puis comme les CSV astronomiques n'ont pas tous les mêmes entêtes on augmentente la robustesse en récupéreant les colonnes par mot clés.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dé-trending longue échelle \n",
    "\n",
    "### Aides statistiques robustes\n",
    "Objectif : obtenir une courbe propre, centrée, régulière, où les petites baisses utiles ne sont pas écrasées.\n",
    "\n",
    "Def mad (Médian absolute deviation) et IQR (écart interquartile) : ignorent l'influence des gros pics avec une dispersion basées sur les quantiles\n",
    "(permet de garder un seuil réaliste pour repérer les vrais point anormaux )\n",
    "\n",
    "Def robust_sigma : Sert à traduire MAD en “σ” robuste compatible. \n",
    "/!\\ 1,4826 = 1 / 0,6745 \n",
    "donc 1,4826 * 0,6745  ≈  1 \n",
    "\n",
    "A savoir 1,4826 est une constante théorique qui vient de la loi normale standard ;)\n",
    "(permet de corrigé la mad pour qu'il soit \"équivalent à un écart type classique)\n",
    "\n",
    "### Sigma-clipping itératif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:27:22.483412Z",
     "iopub.status.busy": "2025-10-04T23:27:22.483091Z",
     "iopub.status.idle": "2025-10-04T23:27:22.517624Z",
     "shell.execute_reply": "2025-10-04T23:27:22.516898Z",
     "shell.execute_reply.started": "2025-10-04T23:27:22.483395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TESS Light Curve — Detrend & Cleaning & Resampling (Kaggle-ready)\n",
    "# ============================================\n",
    "import numpy as np, pandas as pd, warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------- Utils ----------\n",
    "def infer_time_flux_columns(df: pd.DataFrame,\n",
    "                            prefer_time: str | None = None,\n",
    "                            prefer_flux: str | None = None) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Infère les colonnes temps/flux.\n",
    "    - Reconnaît les variantes TESS/Kepler: time_bjd_tdb, btjd/tbjd/bkjd/bjd/jd/mjd/time, etc.\n",
    "    - Flux: flux_norm, pdcsap_flux, sap_flux, flux, flux_raw/flux_corrected, f...\n",
    "    - Si prefer_* fourni et présent, il est utilisé en priorité.\n",
    "    - Fallback: 1) colonnes dont le nom contient 'time' / 'flux' et dtype numérique\n",
    "               2) tentative sur colonnes numériques uniques proches.\n",
    "    \"\"\"\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    # 1) préférences explicites\n",
    "    if prefer_time and prefer_time in df.columns:\n",
    "        time_col = prefer_time\n",
    "    else:\n",
    "        time_candidates = [\n",
    "            # très usuels TESS/Kepler\n",
    "            \"time_bjd_tdb\", \"btjd\", \"tbjd\", \"bkjd\", \"bjd\", \"jd\", \"mjd\",\n",
    "            # génériques\n",
    "            \"time\", \"t\",\n",
    "            # variantes vues parfois\n",
    "            \"time_mission\", \"time_btjd\", \"time_bkjd\", \"time_bjd\", \"time_jd\"\n",
    "        ]\n",
    "        time_col = next((cols[c] for c in time_candidates if c in cols), None)\n",
    "\n",
    "    if prefer_flux and prefer_flux in df.columns:\n",
    "        flux_col = prefer_flux\n",
    "    else:\n",
    "        flux_candidates = [\n",
    "            # usuels\n",
    "            \"flux_norm\", \"pdcsap_flux\", \"sap_flux\", \"flux\",\n",
    "            # variantes fréquentes\n",
    "            \"flux_corrected\", \"flux_raw\", \"f\", \"flux_cal\", \"flux_det\", \"flux_lc\"\n",
    "        ]\n",
    "        flux_col = next((cols[c] for c in flux_candidates if c in cols), None)\n",
    "\n",
    "    # 2) Fallback par motif + dtype numérique\n",
    "    def _first_numeric_col_containing(substr: str):\n",
    "        for c in df.columns:\n",
    "            if substr in c.lower():\n",
    "                try:\n",
    "                    if pd.api.types.is_numeric_dtype(df[c]):\n",
    "                        return c\n",
    "                except Exception:\n",
    "                    continue\n",
    "        return None\n",
    "\n",
    "    if time_col is None:\n",
    "        time_col = _first_numeric_col_containing(\"time\")\n",
    "    if flux_col is None:\n",
    "        flux_col = _first_numeric_col_containing(\"flux\")\n",
    "\n",
    "    # 3) Erreur si toujours rien\n",
    "    if time_col is None or flux_col is None:\n",
    "        raise ValueError(f\"Impossible d'inférer time/flux. Colonnes vues: {list(df.columns)[:10]}\")\n",
    "\n",
    "    return time_col, flux_col\n",
    "\n",
    "\n",
    "# ---------- Sigma clipping robuste ----------\n",
    "def robust_sigma_clip(y: np.ndarray, sigma: float = 5.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Renvoie un masque True pour les points conservés, False pour outliers.\n",
    "    Estimation robuste via médiane + MAD (IQR-like).\n",
    "    \"\"\"\n",
    "    med = np.nanmedian(y)\n",
    "    mad = np.nanmedian(np.abs(y - med))\n",
    "    if mad == 0 or np.isnan(mad):\n",
    "        # fallback std\n",
    "        std = np.nanstd(y)\n",
    "        z = (y - np.nanmean(y)) / (std if std > 0 else 1)\n",
    "    else:\n",
    "        # 1.4826 ~ factor to make MAD comparable to std under normality\n",
    "        z = (y - med) / (1.4826 * mad)\n",
    "    keep = np.isfinite(z) & (np.abs(z) <= sigma)\n",
    "    return keep\n",
    "\n",
    "# ---------- Binning pour tendance lente ----------\n",
    "def bin_median(x: np.ndarray, y: np.ndarray, bin_width_days: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Binning médian pour capturer la tendance de fond sur une échelle donnée (bin_width_days).\n",
    "    \"\"\"\n",
    "    if len(x) == 0:\n",
    "        return x, y\n",
    "    x0, x1 = np.nanmin(x), np.nanmax(x)\n",
    "    if not np.isfinite(x0) or not np.isfinite(x1) or x1 <= x0:\n",
    "        return x, y\n",
    "    edges = np.arange(x0, x1 + bin_width_days, bin_width_days)\n",
    "    idx = np.digitize(x, edges) - 1\n",
    "    xb, yb = [], []\n",
    "    for i in range(len(edges)-1):\n",
    "        m = idx == i\n",
    "        if m.sum() >= 3:\n",
    "            xb.append(np.nanmedian(x[m]))\n",
    "            yb.append(np.nanmedian(y[m]))\n",
    "    return np.array(xb), np.array(yb)\n",
    "\n",
    "# ---------- Tendance par spline cubique ----------\n",
    "def fit_spline_trend(time: np.ndarray, flux: np.ndarray,\n",
    "                     bin_width_hours: float = 6.0,\n",
    "                     spline_smooth_factor: Optional[float] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Estime la tendance lente via:\n",
    "    1) bin médian (par ex. 6h) pour lisser le bruit haute fréquence,\n",
    "    2) spline cubique lissée (UnivariateSpline, k=3) ajustée sur ces points binnés,\n",
    "    3) évalue la spline aux temps originaux.\n",
    "    \"\"\"\n",
    "    # Convertir bin en jours (TESS/Kepler: temps en jours)\n",
    "    bin_w_days = bin_width_hours / 24.0\n",
    "    xb, yb = bin_median(time, flux, bin_w_days)\n",
    "\n",
    "    if len(xb) < 5:\n",
    "        # Pas assez de points binned -> fallback à une spline directe (ou médiane)\n",
    "        med = np.nanmedian(flux)\n",
    "        return np.full_like(flux, med)\n",
    "\n",
    "    # Choix d'un facteur de lissage raisonnable s si non fourni\n",
    "    # s ~ lambda * N, où lambda ~ variance résiduelle attendue\n",
    "    # On met un s par défaut conservatif (proportionnel à nb de points binnés).\n",
    "    if spline_smooth_factor is None:\n",
    "        spline_smooth_factor = max(1e-3, 0.001 * len(xb))\n",
    "\n",
    "    try:\n",
    "        spl = UnivariateSpline(xb, yb, k=3, s=spline_smooth_factor)\n",
    "        trend = spl(time)\n",
    "    except Exception:\n",
    "        # Fallback: moyenne mobile grossière (au cas où spline échoue)\n",
    "        trend = pd.Series(flux).rolling(window=101, min_periods=1, center=True).median().values\n",
    "\n",
    "    return trend\n",
    "\n",
    "# ---------- Normalisation robuste ----------\n",
    "def robust_scale(y: np.ndarray) -> np.ndarray:\n",
    "    med = np.nanmedian(y)\n",
    "    q25, q75 = np.nanpercentile(y, [25, 75])\n",
    "    iqr = q75 - q25\n",
    "    if not np.isfinite(iqr) or iqr == 0:\n",
    "        iqr = np.nanstd(y)\n",
    "        if not np.isfinite(iqr) or iqr == 0:\n",
    "            iqr = 1.0\n",
    "    return (y - med) / iqr\n",
    "\n",
    "# ---------- Resampling uniforme ----------\n",
    "def resample_uniform(time_days: np.ndarray,\n",
    "                     flux: np.ndarray,\n",
    "                     step_minutes: float = 10.0) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Ré-échantillonne (interpolation linéaire) sur une grille régulière de pas = step_minutes.\n",
    "    Gère les NaN: on interpole seulement entre bornes valides.\n",
    "    \"\"\"\n",
    "    if len(time_days) < 3:\n",
    "        return time_days, flux\n",
    "\n",
    "    t0, t1 = np.nanmin(time_days), np.nanmax(time_days)\n",
    "    if not np.isfinite(t0) or not np.isfinite(t1) or t1 <= t0:\n",
    "        return time_days, flux\n",
    "\n",
    "    dt = step_minutes / (24.0 * 60.0)\n",
    "    grid = np.arange(t0, t1 + 0.5*dt, dt)\n",
    "\n",
    "    # Masque points valides\n",
    "    m = np.isfinite(time_days) & np.isfinite(flux)\n",
    "    if m.sum() < 2:\n",
    "        return grid, np.full_like(grid, np.nan)\n",
    "\n",
    "    # Tri (sécurité)\n",
    "    order = np.argsort(time_days[m])\n",
    "    t_sorted = time_days[m][order]\n",
    "    f_sorted = flux[m][order]\n",
    "\n",
    "    # Interp linéaire\n",
    "    f_grid = np.interp(grid, t_sorted, f_sorted, left=np.nan, right=np.nan)\n",
    "\n",
    "    return grid, f_grid\n",
    "\n",
    "# ---------- Pipeline complet pour une courbe ----------\n",
    "@dataclass\n",
    "class DetrendConfig:\n",
    "    sigma: float = 5.0\n",
    "    bin_width_hours: float = 6.0\n",
    "    spline_smooth_factor: Optional[float] = None\n",
    "    resample_step_minutes: float = 10.0\n",
    "    divide_trend: bool = True  # True => flux_detrended = flux / trend (puis -1), sinon flux - trend\n",
    "\n",
    "def preprocess_single_lightcurve(df_one: pd.DataFrame, time_col: str, flux_col: str,\n",
    "                                 cfg: DetrendConfig) -> Dict[str, np.ndarray]:\n",
    "    # Extraire\n",
    "    t = df_one[time_col].astype(float).values\n",
    "    f = df_one[flux_col].astype(float).values\n",
    "\n",
    "    # 1) Sigma clipping robuste (5σ)\n",
    "    keep = robust_sigma_clip(f, sigma=cfg.sigma)\n",
    "    t1, f1 = t[keep], f[keep]\n",
    "\n",
    "    # 2) Tendance lente via spline sur binned medians\n",
    "    trend = fit_spline_trend(t1, f1, bin_width_hours=cfg.bin_width_hours,\n",
    "                             spline_smooth_factor=cfg.spline_smooth_factor)\n",
    "\n",
    "    # 3) Flatten: division ou soustraction de tendance\n",
    "    if cfg.divide_trend:\n",
    "        # éviter division par zéro\n",
    "        trend_safe = np.where(np.isfinite(trend) & (trend != 0), trend, np.nanmedian(trend))\n",
    "        f_flat = (f1 / trend_safe) - 1.0\n",
    "    else:\n",
    "        f_flat = f1 - trend\n",
    "\n",
    "    # 4) Normalisation robuste\n",
    "    f_norm = robust_scale(f_flat)\n",
    "\n",
    "    # 5) Resampling uniforme (10 minutes)\n",
    "    t_uni, f_uni = resample_uniform(t1, f_norm, step_minutes=cfg.resample_step_minutes)\n",
    "\n",
    "    return {\n",
    "        \"time_raw\": t, \"flux_raw\": f, \"mask_kept\": keep,\n",
    "        \"time_clipped\": t1, \"flux_clipped\": f1, \"trend\": trend,\n",
    "        \"flux_flat\": f_flat, \"flux_norm\": f_norm,\n",
    "        \"time_uniform\": t_uni, \"flux_uniform\": f_uni\n",
    "    }\n",
    "\n",
    "# ---------- Visualisation ----------\n",
    "def quick_compare_plot(proc: Dict[str, np.ndarray], title: str = \"\", max_points: int = 100000):\n",
    "    t_raw, f_raw = proc[\"time_raw\"], proc[\"flux_raw\"]\n",
    "    t1, f1 = proc[\"time_clipped\"], proc[\"flux_clipped\"]\n",
    "    trend = proc[\"trend\"]\n",
    "    t_uni, f_uni = proc[\"time_uniform\"], proc[\"flux_uniform\"]\n",
    "\n",
    "    # downsample for speed if huge\n",
    "    def thin(x, y, k=5):\n",
    "        if len(x) <= max_points:\n",
    "            return x, y\n",
    "        step = max(1, len(x)//max_points)\n",
    "        return x[::step], y[::step]\n",
    "\n",
    "    t_raw_, f_raw_ = thin(t_raw, f_raw)\n",
    "    t1_, f1_ = thin(t1, f1)\n",
    "    t_uni_, f_uni_ = thin(t_uni, f_uni)\n",
    "\n",
    "    plt.figure(figsize=(12,9))\n",
    "    # A. Brut + outliers\n",
    "    ax = plt.subplot(3,1,1)\n",
    "    ax.plot(t_raw_, f_raw_, \".\", ms=2, alpha=0.6)\n",
    "    ax.set_title(f\"[A] Courbe brute (avec outliers) — {title}\")\n",
    "    ax.set_xlabel(\"Temps (jours)\")\n",
    "    ax.set_ylabel(\"Flux\")\n",
    "\n",
    "    # B. Après clipping + tendance spline\n",
    "    ax = plt.subplot(3,1,2)\n",
    "    ax.plot(t1_, f1_, \".\", ms=2, alpha=0.6, label=\"Clippé (5σ)\")\n",
    "    # évaluer la trend sur t1_ pour overlay propre\n",
    "    try:\n",
    "        # Interp de la tendance pour l'affichage\n",
    "        tr_disp = np.interp(t1_, t1, trend, left=np.nan, right=np.nan)\n",
    "        ax.plot(t1_, tr_disp, \"-\", lw=1.5, label=\"Tendance (spline)\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    ax.set_title(\"[B] Outliers retirés + tendance lente estimée\")\n",
    "    ax.set_xlabel(\"Temps (jours)\"); ax.set_ylabel(\"Flux\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    # C. Flatten + normalisé + ré-échantillonné\n",
    "    ax = plt.subplot(3,1,3)\n",
    "    ax.plot(t_uni_, f_uni_, \".\", ms=2, alpha=0.7, label=\"Flatten+Norm+Uniform(10min)\")\n",
    "    ax.set_title(\"[C] Dé-trend + normalisation (médiane/IQR) + cadence uniforme\")\n",
    "    ax.set_xlabel(\"Temps (jours)\"); ax.set_ylabel(\"Flux normalisé\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ---------- Chargement & dispatch multi-cibles ----------\n",
    "def load_tess_csv(path: str, n_rows: Optional[int] = None) -> pd.DataFrame:\n",
    "    # lecture flexible (le séparateur peut être comma ou autre)\n",
    "    try:\n",
    "        return pd.read_csv(path, nrows=n_rows)\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, nrows=n_rows, engine=\"python\", sep=None)\n",
    "\n",
    "def infer_id_column(df: pd.DataFrame) -> Optional[str]:\n",
    "    candidates = [\n",
    "        \"target_id\",\"tic\",\"tic_id\",\"ticid\",     # TESS\n",
    "        \"kepid\",\"kic\",\"epic\",                   # Kepler/K2\n",
    "        \"object_id\",\"object\",\"source_id\",\"star_id\",\"gaia_source_id\",\"id\"\n",
    "    ]\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    for key in candidates:\n",
    "        if key in cols_lower:\n",
    "            return cols_lower[key]\n",
    "\n",
    "    # Fallback: choose a non-time/flux column with reasonable cardinality\n",
    "    for c in df.columns:\n",
    "        cl = c.lower()\n",
    "        if any(k in cl for k in [\"time\",\"flux\",\"err\",\"error\",\"unc\",\"mag\",\"cadence\"]):\n",
    "            continue\n",
    "        nunique = df[c].nunique(dropna=True)\n",
    "        if 1 < nunique < 0.5 * len(df):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def group_iter(df: pd.DataFrame) -> List[Tuple[str, pd.DataFrame]]:\n",
    "    id_col = infer_id_column(df)\n",
    "    try:\n",
    "        time_col, _ = infer_time_flux_columns(df)\n",
    "    except Exception:\n",
    "        time_col = None\n",
    "\n",
    "    if id_col is None:\n",
    "        sub = df if time_col is None else df.sort_values(time_col)\n",
    "        return [(\"no_id\", sub)]\n",
    "\n",
    "    groups = []\n",
    "    for gid_val, sub in df.groupby(id_col, sort=False):\n",
    "        sub_sorted = sub if time_col is None else sub.sort_values(time_col)\n",
    "        groups.append((f\"{id_col}={gid_val}\", sub_sorted))\n",
    "    return groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:27:22.520177Z",
     "iopub.status.busy": "2025-10-04T23:27:22.519540Z",
     "iopub.status.idle": "2025-10-04T23:27:26.426421Z",
     "shell.execute_reply": "2025-10-04T23:27:26.425623Z",
     "shell.execute_reply.started": "2025-10-04T23:27:22.520150Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/TESS_standardized_lightcurves.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 286\u001b[39m, in \u001b[36mload_tess_csv\u001b[39m\u001b[34m(path, n_rows)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucho\\anaconda3\\envs\\cours\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucho\\anaconda3\\envs\\cours\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucho\\anaconda3\\envs\\cours\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucho\\anaconda3\\envs\\cours\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucho\\anaconda3\\envs\\cours\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m     \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m     handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m     \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/data/TESS_standardized_lightcurves.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -------- Exemple : charger, traiter 3 cibles, afficher avant/après --------\u001b[39;00m\n\u001b[32m      2\u001b[39m input_path = \u001b[33m\"\u001b[39m\u001b[33m/data/TESS_standardized_lightcurves.csv\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# <- adapte si besoin\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df = \u001b[43mload_tess_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m time_col, flux_col = infer_time_flux_columns(df)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mColonnes détectées:\u001b[39m\u001b[33m\"\u001b[39m, time_col, \u001b[33m\"\u001b[39m\u001b[33m|\u001b[39m\u001b[33m\"\u001b[39m, flux_col)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 288\u001b[39m, in \u001b[36mload_tess_csv\u001b[39m\u001b[34m(path, n_rows)\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.read_csv(path, nrows=n_rows)\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucho\\anaconda3\\envs\\cours\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucho\\anaconda3\\envs\\cours\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucho\\anaconda3\\envs\\cours\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucho\\anaconda3\\envs\\cours\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucho\\anaconda3\\envs\\cours\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/data/TESS_standardized_lightcurves.csv'"
     ]
    }
   ],
   "source": [
    "# -------- Exemple : charger, traiter 3 cibles, afficher avant/après --------\n",
    "input_path = \"./data/TESS_standardized_lightcurves.csv\"  # <- adapte si besoin\n",
    "df = load_tess_csv(input_path)\n",
    "\n",
    "time_col, flux_col = infer_time_flux_columns(df)\n",
    "print(\"Colonnes détectées:\", time_col, \"|\", flux_col)\n",
    "\n",
    "cfg = DetrendConfig(\n",
    "    sigma=5.0,               # clipping robuste 5σ (pics isolés)\n",
    "    bin_width_hours=6.0,     # binning 6h pour la tendance lente\n",
    "    spline_smooth_factor=None, # laisse l'auto-choix raisonnable\n",
    "    resample_step_minutes=10.0, # cadence uniforme 10 minutes\n",
    "    divide_trend=True        # flux/Trend - 1 (flatten multiplicatif)\n",
    ")\n",
    "\n",
    "for i, (gid, sub) in enumerate(group_iter(df)):\n",
    "    if i >= 3: break  # démontre sur 3 cibles\n",
    "    print(f\"\\n=== Traitement {gid} ===\")\n",
    "    proc = preprocess_single_lightcurve(sub.sort_values(time_col), time_col, flux_col, cfg)\n",
    "    quick_compare_plot(proc, title=gid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Détection de périodes candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:27:26.428432Z",
     "iopub.status.busy": "2025-10-04T23:27:26.427640Z",
     "iopub.status.idle": "2025-10-04T23:27:27.767643Z",
     "shell.execute_reply": "2025-10-04T23:27:27.766771Z",
     "shell.execute_reply.started": "2025-10-04T23:27:26.428397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# BLS Period Search (candidats de périodes) — Kaggle-ready\n",
    "# S'appuie sur les sorties du prétraitement:\n",
    "#   t = proc[\"time_uniform\"] (jours), y = proc[\"flux_uniform\"] (sans tendance, normalisé)\n",
    "# Nécessite: astropy (installé sur Kaggle par défaut; sinon pip install astropy)\n",
    "# ==========================================================\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from astropy.timeseries import BoxLeastSquares\n",
    "\n",
    "\n",
    "def _finite_mask(*arrs):\n",
    "    m = np.ones_like(arrs[0], dtype=bool)\n",
    "    for a in arrs:\n",
    "        m &= np.isfinite(a)\n",
    "    return m\n",
    "\n",
    "def estimate_period_bounds(t_days: np.ndarray, min_hours: float = 7.0, max_frac_baseline: float = 0.9):\n",
    "    \"\"\"\n",
    "    Heuristique simple:\n",
    "    - période min ~ 7 h (évite d'ajuster le bruit haute fréquence)\n",
    "    - période max ~ 90% de la base temporelle (évite d'atteindre le bord)\n",
    "    \"\"\"\n",
    "    baseline_days = np.nanmax(t_days) - np.nanmin(t_days)\n",
    "    p_min = max(min_hours / 24.0, 0.05)                # >= 0.05 j (≈1.2 h) en ultime secours\n",
    "    p_max = max(p_min * 2, baseline_days * max_frac_baseline)\n",
    "    return p_min, p_max, baseline_days\n",
    "\n",
    "def duration_grid_hours(min_h=1.0, max_h=12.0, n=10):\n",
    "    \"\"\"Durées de transit testées par BLS (en heures → converties en jours).\"\"\"\n",
    "    durs_h = np.geomspace(min_h, max_h, n)\n",
    "    return durs_h / 24.0\n",
    "\n",
    "def run_bls_on_proc(proc: dict,\n",
    "                    n_periods: int = 5000,\n",
    "                    min_period_hours: float = 7.0,\n",
    "                    max_period_frac_baseline: float = 0.9,\n",
    "                    durations_hours: tuple = (1.0, 12.0),\n",
    "                    n_durations: int = 10,\n",
    "                    top_k: int = 3):\n",
    "    \"\"\"\n",
    "    Lance BLS (astropy) sur une courbe déjà détrendée/normalisée/ré-échantillonnée.\n",
    "    Retourne dict avec:\n",
    "      - 'results': DataFrame top_k candidats (period, t0, duration, depth, power, snr-like)\n",
    "      - 'bls': l'objet BLS\n",
    "      - 'periodogram': dict avec arrays pour plot (period, power, duration_opt, t0_opt)\n",
    "    \"\"\"\n",
    "    t = np.asarray(proc[\"time_uniform\"])\n",
    "    y = np.asarray(proc[\"flux_uniform\"])\n",
    "    m = _finite_mask(t, y)\n",
    "    t, y = t[m], y[m]\n",
    "\n",
    "    if len(t) < 100 or (np.nanmax(t) - np.nanmin(t)) <= 0:\n",
    "        raise ValueError(\"Série trop courte ou dégénérée pour BLS.\")\n",
    "\n",
    "    # Borne de période\n",
    "    pmin, pmax, baseline_days = estimate_period_bounds(t, min_hours=min_period_hours,\n",
    "                                                       max_frac_baseline=max_period_frac_baseline)\n",
    "    # Durées testées\n",
    "    durs = duration_grid_hours(min_h=durations_hours[0], max_h=durations_hours[1], n=n_durations)\n",
    "\n",
    "    # Astropy BLS\n",
    "    bls = BoxLeastSquares(t, y)\n",
    "    # On utilise autopower (grille de fréquences implicite) avec nos durées\n",
    "    power = bls.autopower(durs, minimum_period=pmin, maximum_period=pmax, objective='snr')\n",
    "\n",
    "    # Récupère le pic principal et quelques suivants\n",
    "    # Tri des indices par 'power.power' décroissant\n",
    "    order = np.argsort(power.power)[::-1]\n",
    "    top_idx = order[:max(1, top_k)]\n",
    "\n",
    "    rows = []\n",
    "    for idx in top_idx:\n",
    "        P = power.period[idx]\n",
    "        dur = power.duration[idx]\n",
    "        t0 = power.transit_time[idx]\n",
    "        powv = power.power[idx]\n",
    "\n",
    "        # Raffinement local autour de ce candidat\n",
    "        model = bls.model(t, P, dur, t0)\n",
    "        depth = np.nanmedian(y - model)  # estimation grossière; on fait mieux via fit()\n",
    "        # Fit précis (recalcule t0, depth, duration)\n",
    "        try:\n",
    "            fit = bls.fit(P, dur, t0)\n",
    "            t0_ref, dur_ref, depth_ref = fit['transit_time'], fit['duration'], fit['depth']\n",
    "            snr_ref = fit.get('depth_snr', np.nan)\n",
    "            dur, t0, depth, snr_like = dur_ref, t0_ref, depth_ref, snr_ref\n",
    "        except Exception:\n",
    "            snr_like = powv  # fallback\n",
    "\n",
    "        rows.append(dict(\n",
    "            period=P, duration=dur, t0=t0, depth=depth, power=powv, snr=snr_like\n",
    "        ))\n",
    "\n",
    "    results = pd.DataFrame(rows).sort_values(\n",
    "        by=[\"snr\",\"power\"], ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # Détection “single-transit-like” (heuristique):\n",
    "    # si la meilleure période est > ~70% de la baseline, fort risque single-transit\n",
    "    single_like = False\n",
    "    if len(results):\n",
    "        if results.loc[0, \"period\"] > 0.7 * baseline_days:\n",
    "            single_like = True\n",
    "\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"bls\": bls,\n",
    "        \"periodogram\": {\n",
    "            \"period\": power.period,\n",
    "            \"power\": power.power,\n",
    "            \"duration_opt\": power.duration,\n",
    "            \"t0_opt\": power.transit_time,\n",
    "            \"pmin\": pmin, \"pmax\": pmax, \"baseline_days\": baseline_days,\n",
    "            \"single_transit_like\": single_like\n",
    "        }\n",
    "    }\n",
    "\n",
    "def plot_bls_periodogram(bls_out: dict, top_n: int = 1, title: str = \"\"):\n",
    "    per = bls_out[\"periodogram\"][\"period\"]\n",
    "    powv = bls_out[\"periodogram\"][\"power\"]\n",
    "    pmin, pmax = bls_out[\"periodogram\"][\"pmin\"], bls_out[\"periodogram\"][\"pmax\"]\n",
    "    single_like = bls_out[\"periodogram\"][\"single_transit_like\"]\n",
    "\n",
    "    res = bls_out[\"results\"].copy()\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(per, powv, lw=1)\n",
    "    if len(res):\n",
    "        for i in range(min(top_n, len(res))):\n",
    "            P = res.loc[i, \"period\"]\n",
    "            plt.axvline(P, ls=\"--\", alpha=0.6)\n",
    "    plt.xlim(pmin, pmax)\n",
    "    plt.xlabel(\"Période (jours)\"); plt.ylabel(\"Puissance (objective='snr')\")\n",
    "    ttl = \"[BLS] Periodogram\"\n",
    "    if single_like: ttl += \" — (single-transit-like ?)\"\n",
    "    if title: ttl += f\" — {title}\"\n",
    "    plt.title(ttl)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "def plot_phase_fold(proc: dict, bls_out: dict, k: int = 0, title: str = \"\"):\n",
    "    \"\"\"Affiche la courbe pliée sur la période candidate k et le modèle en boîte.\"\"\"\n",
    "    if len(bls_out[\"results\"]) == 0:\n",
    "        print(\"Pas de candidat BLS.\")\n",
    "        return\n",
    "    P = bls_out[\"results\"].loc[k, \"period\"]\n",
    "    t0 = bls_out[\"results\"].loc[k, \"t0\"]\n",
    "    dur = bls_out[\"results\"].loc[k, \"duration\"]\n",
    "\n",
    "    t = np.asarray(proc[\"time_uniform\"]); y = np.asarray(proc[\"flux_uniform\"])\n",
    "    m = _finite_mask(t, y); t, y = t[m], y[m]\n",
    "\n",
    "    # Phase folding dans [-0.5, 0.5)\n",
    "    phase = ((t - t0 + 0.5 * P) % P) / P - 0.5\n",
    "\n",
    "    # Modèle en boîte pour overlay\n",
    "    bls = bls_out[\"bls\"]\n",
    "    model = bls.model(t, P, dur, t0)\n",
    "\n",
    "    # Bin de la courbe pliée pour lisser le bruit\n",
    "    nbins = 200\n",
    "    bins = np.linspace(-0.5, 0.5, nbins+1)\n",
    "    idx = np.digitize(phase, bins) - 1\n",
    "    ph_b, y_b = [], []\n",
    "    for i in range(nbins):\n",
    "        m = idx == i\n",
    "        if m.sum() >= 5:\n",
    "            ph_b.append(np.nanmedian(phase[m]))\n",
    "            y_b.append(np.nanmedian(y[m]))\n",
    "    ph_b, y_b = np.array(ph_b), np.array(y_b)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(phase, y, \".\", ms=2, alpha=0.25, label=\"Pliée (points)\")\n",
    "    if len(ph_b):\n",
    "        plt.plot(ph_b, y_b, \"-\", lw=1.5, label=\"Pliée (binned médian)\")\n",
    "    # Overlay du modèle: on doit aussi le plier\n",
    "    phase_m = ((t - t0 + 0.5 * P) % P) / P - 0.5\n",
    "    # On bin le modèle comme la courbe\n",
    "    idxm = np.digitize(phase_m, bins) - 1\n",
    "    mod_b = []\n",
    "    for i in range(nbins):\n",
    "        m = idxm == i\n",
    "        if m.sum() >= 5:\n",
    "            mod_b.append(np.nanmedian(model[m]))\n",
    "    if len(mod_b) == len(y_b):\n",
    "        plt.plot(ph_b, mod_b, \"-\", lw=2, alpha=0.9, label=\"Modèle BLS\")\n",
    "\n",
    "    plt.xlabel(\"Phase (cycles)\"); plt.ylabel(\"Flux normalisé\")\n",
    "    ttl = f\"[BLS] Fold P={P:.5f} j, dur={dur*24:.2f} h\"\n",
    "    if title: ttl += f\" — {title}\"\n",
    "    plt.title(ttl)\n",
    "    plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:27:27.769613Z",
     "iopub.status.busy": "2025-10-04T23:27:27.768741Z",
     "iopub.status.idle": "2025-10-04T23:27:32.453550Z",
     "shell.execute_reply": "2025-10-04T23:27:32.452458Z",
     "shell.execute_reply.started": "2025-10-04T23:27:27.769586Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] P_min ≈ 0.2917 j (7.00 h) | P_max ≈ 24.66 j\n",
      "[Info] Durées testées (heures): [1.00 .. 5.60]\n",
      "\n",
      "=== Candidats BLS (Top) ===\n",
      "#1  P = 1.866987 jours  (44.81 h) | durée ~ 1.20 h | SNR ≈ 13.63\n",
      "#2  P = 1.867374 jours  (44.82 h) | durée ~ 1.20 h | SNR ≈ 13.53\n",
      "#3  P = 1.867568 jours  (44.82 h) | durée ~ 1.20 h | SNR ≈ 13.53\n"
     ]
    }
   ],
   "source": [
    "# === Cellule de vérification BLS (safe) : calcule P et évite l'erreur durée > période ===\n",
    "# Hypothèses: 'proc' (prétraité), 'estimate_period_bounds', 'run_bls_on_proc' existent déjà.\n",
    "\n",
    "# 1) Estimer les bornes de période avec la même heuristique que BLS\n",
    "t_uni = np.asarray(proc[\"time_uniform\"])\n",
    "pmin, pmax, baseline_days = estimate_period_bounds(t_uni, min_hours=7.0, max_frac_baseline=0.9)\n",
    "\n",
    "# 2) Forcer une durée max < période min (contrainte astropy BLS)\n",
    "max_dur_hours_safe = min(12.0, 0.8 * pmin * 24.0)  # 80% de P_min\n",
    "min_dur_hours = 1.0\n",
    "if max_dur_hours_safe <= min_dur_hours:\n",
    "    # si la période min est trop courte, on réduit min_dur pour rester valide\n",
    "    min_dur_hours = max(0.25, 0.2 * max_dur_hours_safe)\n",
    "\n",
    "print(f\"[Info] P_min ≈ {pmin:.4f} j ({pmin*24:.2f} h) | P_max ≈ {pmax:.2f} j\")\n",
    "print(f\"[Info] Durées testées (heures): [{min_dur_hours:.2f} .. {max_dur_hours_safe:.2f}]\")\n",
    "\n",
    "# 3) Lancer BLS avec des durées sûres\n",
    "bls_out = run_bls_on_proc(\n",
    "    proc,\n",
    "    n_periods=5000,\n",
    "    min_period_hours=24.0 * pmin,              # garde cohérent avec pmin calculé (en heures)\n",
    "    max_period_frac_baseline=0.9,\n",
    "    durations_hours=(min_dur_hours, max_dur_hours_safe),\n",
    "    n_durations=10,\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "# 4) Imprimer les périodes candidates\n",
    "res = bls_out[\"results\"]\n",
    "if len(res) == 0:\n",
    "    print(\"BLS n'a retourné aucun candidat (résultats vides).\")\n",
    "else:\n",
    "    print(\"\\n=== Candidats BLS (Top) ===\")\n",
    "    for i in range(len(res)):\n",
    "        P = float(res.loc[i, \"period\"])\n",
    "        dur_h = float(res.loc[i, \"duration\"] * 24.0)\n",
    "        snr = res.loc[i, \"snr\"]\n",
    "        print(f\"#{i+1}  P = {P:.6f} jours  ({P*24:.2f} h) | durée ~ {dur_h:.2f} h | SNR ≈ {snr:.2f}\")\n",
    "\n",
    "    if bls_out[\"periodogram\"][\"single_transit_like\"]:\n",
    "        print(\"\\n[Note] Le meilleur P est proche de la durée de base : cas 'single-transit-like' possible.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction des vues multi-résolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:27:32.455002Z",
     "iopub.status.busy": "2025-10-04T23:27:32.454686Z",
     "iopub.status.idle": "2025-10-04T23:27:32.484084Z",
     "shell.execute_reply": "2025-10-04T23:27:32.483357Z",
     "shell.execute_reply.started": "2025-10-04T23:27:32.454974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- Utils: resampling sur N points fixes ----------\n",
    "def _resample_to_fixed_length(x, y, n_points=2001):\n",
    "    \"\"\"Interpole y(x) sur une grille régulière de n_points entre min(x) et max(x).\"\"\"\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    if m.sum() < 2:\n",
    "        return np.linspace(0, 1, n_points), np.full(n_points, np.nan)\n",
    "    xs = np.sort(x[m])\n",
    "    ys = y[m][np.argsort(x[m])]\n",
    "    grid = np.linspace(xs.min(), xs.max(), n_points)\n",
    "    yg = np.interp(grid, xs, ys)\n",
    "    return grid, yg\n",
    "\n",
    "def _bin_median(x, y, nbins):\n",
    "    \"\"\"Binning médian (utile pour réduire le bruit après pliage).\"\"\"\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[m], y[m]\n",
    "    if len(x) == 0:\n",
    "        return np.linspace(-0.5, 0.5, nbins), np.full(nbins, np.nan)\n",
    "    edges = np.linspace(x.min(), x.max(), nbins+1)\n",
    "    idx = np.digitize(x, edges) - 1\n",
    "    xb, yb = [], []\n",
    "    for i in range(nbins):\n",
    "        mask = idx == i\n",
    "        if mask.sum() >= 3:\n",
    "            xb.append(np.nanmedian(x[mask]))\n",
    "            yb.append(np.nanmedian(y[mask]))\n",
    "    if len(xb) < 2:\n",
    "        # fallback interpolation simple\n",
    "        grid = np.linspace(x.min(), x.max(), nbins)\n",
    "        yg = np.interp(grid, x, y)\n",
    "        return grid, yg\n",
    "    return np.array(xb), np.array(yb)\n",
    "\n",
    "# ---------- Extraction (P, t0, dur) à partir de bls_out ou paramètres ----------\n",
    "def _pick_bls_candidate(bls_out, k=0):\n",
    "    \"\"\"Renvoie (P, t0, dur) en jours si disponible, sinon (None, None, None).\"\"\"\n",
    "    if bls_out is None:\n",
    "        return None, None, None\n",
    "    res = bls_out.get(\"results\", pd.DataFrame())\n",
    "    if len(res) == 0:\n",
    "        return None, None, None\n",
    "    P = float(res.loc[k, \"period\"])\n",
    "    t0 = float(res.loc[k, \"t0\"])\n",
    "    dur = float(res.loc[k, \"duration\"])\n",
    "    return P, t0, dur\n",
    "\n",
    "# ---------- Construction des vues ----------\n",
    "def build_multires_views(proc: dict,\n",
    "                         bls_out: dict | None = None,\n",
    "                         P: float | None = None,\n",
    "                         t0: float | None = None,\n",
    "                         dur: float | None = None,\n",
    "                         N_GLOBAL: int = 2001,\n",
    "                         N_LOCAL: int = 201,\n",
    "                         window_factor: float = 2.0,\n",
    "                         median_bin_local: bool = True):\n",
    "    \"\"\"\n",
    "    Renvoie un dict avec:\n",
    "      - 'global_time', 'global_flux' (N_GLOBAL)\n",
    "      - 'fold_phase', 'fold_flux' (pliage sur P, binned à N_GLOBAL/≈2000)\n",
    "      - 'local_phase', 'local_flux' (fenêtre ± window_factor*dur autour du transit, N_LOCAL)\n",
    "      - 'meta': {'P','t0','dur','has_period','single_transit_like'}\n",
    "    \"\"\"\n",
    "    # 0) Entrées\n",
    "    t = np.asarray(proc[\"time_uniform\"])\n",
    "    y = np.asarray(proc[\"flux_uniform\"])\n",
    "    m = np.isfinite(t) & np.isfinite(y)\n",
    "    t, y = t[m], y[m]\n",
    "\n",
    "    views = {\"meta\": {}}\n",
    "\n",
    "    # 1) Vue Globale (contexte longue durée)\n",
    "    g_time, g_flux = _resample_to_fixed_length(t, y, n_points=N_GLOBAL)\n",
    "    views[\"global_time\"] = g_time\n",
    "    views[\"global_flux\"] = g_flux\n",
    "\n",
    "    # 2) Déterminer P, t0, dur\n",
    "    if P is None or t0 is None or dur is None:\n",
    "        P_bls, t0_bls, dur_bls = _pick_bls_candidate(bls_out, k=0)\n",
    "        if P is None:  P = P_bls\n",
    "        if t0 is None: t0 = t0_bls\n",
    "        if dur is None: dur = dur_bls\n",
    "\n",
    "    single_like = False\n",
    "    if bls_out is not None and \"periodogram\" in bls_out:\n",
    "        single_like = bool(bls_out[\"periodogram\"].get(\"single_transit_like\", False))\n",
    "\n",
    "    has_period = (P is not None) and (np.isfinite(P)) and (P > 0) and (dur is not None) and (dur > 0)\n",
    "\n",
    "    views[\"meta\"].update(dict(P=P, t0=t0, dur=dur, has_period=has_period, single_transit_like=single_like))\n",
    "\n",
    "    # 3) Si période connue: Vue Pliée + Vue Locale\n",
    "    if has_period:\n",
    "        # 3a) Pliage en phase dans [-0.5, 0.5)\n",
    "        phase = ((t - t0 + 0.5 * P) % P) / P - 0.5\n",
    "\n",
    "        # Pliée \"globale\" (pour visualisation): binned médian ~ 2000 points\n",
    "        fold_n = min(2000, max(200, N_GLOBAL))  # nombre raisonnable\n",
    "        if median_bin_local:\n",
    "            ph_b, y_b = _bin_median(phase, y, nbins=fold_n)\n",
    "        else:\n",
    "            # simple interpolation sur grille régulière de phase\n",
    "            grid = np.linspace(-0.5, 0.5, fold_n)\n",
    "            order = np.argsort(phase)\n",
    "            ph_sorted, y_sorted = phase[order], y[order]\n",
    "            y_interp = np.interp(grid, ph_sorted, y_sorted)\n",
    "            ph_b, y_b = grid, y_interp\n",
    "\n",
    "        views[\"fold_phase\"] = ph_b\n",
    "        views[\"fold_flux\"]  = y_b\n",
    "\n",
    "        # 3b) Vue Locale (fenêtre centrée sur transit principal)\n",
    "        # Largeur fenêtre en phase = (window_factor * dur) / P\n",
    "        half_width_phase = float(window_factor * dur / P)  # typiquement ~ 2*dur/P\n",
    "        # Borner pour rester dans l'intervalle de phase\n",
    "        half_width_phase = float(min(0.45, max(0.01, half_width_phase)))\n",
    "\n",
    "        sel = (phase >= -half_width_phase) & (phase <= half_width_phase)\n",
    "        if sel.sum() < 10:\n",
    "            # fallback: élargir un peu la fenêtre si trop peu de points\n",
    "            half_width_phase = min(0.45, half_width_phase * 1.5)\n",
    "            sel = (phase >= -half_width_phase) & (phase <= half_width_phase)\n",
    "\n",
    "        ph_loc, y_loc = phase[sel], y[sel]\n",
    "        if median_bin_local:\n",
    "            ph_loc_b, y_loc_b = _bin_median(ph_loc, y_loc, nbins=N_LOCAL)\n",
    "        else:\n",
    "            # interpolation uniforme dans la fenêtre locale\n",
    "            grid_loc = np.linspace(-half_width_phase, half_width_phase, N_LOCAL)\n",
    "            if len(ph_loc) >= 2:\n",
    "                order = np.argsort(ph_loc)\n",
    "                phs, ys = ph_loc[order], y_loc[order]\n",
    "                y_loc_b = np.interp(grid_loc, phs, ys)\n",
    "            else:\n",
    "                y_loc_b = np.full_like(grid_loc, np.nan)\n",
    "            ph_loc_b = grid_loc\n",
    "            \n",
    "        if len(ph_loc_b) != N_LOCAL:\n",
    "            if len(ph_loc_b) >= 2:\n",
    "                grid_fix = np.linspace(-half_width_phase, half_width_phase, N_LOCAL)\n",
    "                order = np.argsort(ph_loc_b)\n",
    "                ph_sorted, y_sorted = np.asarray(ph_loc_b)[order], np.asarray(y_loc_b)[order]\n",
    "                y_fix = np.interp(grid_fix, ph_sorted, y_sorted)\n",
    "                ph_loc_b, y_loc_b = grid_fix, y_fix\n",
    "            else:\n",
    "                # trop peu de points -> on génère une fenêtre plate (zeros) pour rester aligné\n",
    "                ph_loc_b = np.linspace(-half_width_phase, half_width_phase, N_LOCAL)\n",
    "                y_loc_b  = np.zeros_like(ph_loc_b, dtype=float)\n",
    "\n",
    "        views[\"local_phase\"] = ph_loc_b\n",
    "        views[\"local_flux\"]  = y_loc_b\n",
    "\n",
    "    else:\n",
    "        # Pas de période fiable -> pas de vues pliées\n",
    "        views[\"fold_phase\"] = None\n",
    "        views[\"fold_flux\"]  = None\n",
    "        views[\"local_phase\"] = None\n",
    "        views[\"local_flux\"]  = None\n",
    "\n",
    "    # 4) Petit résumé console\n",
    "    print(\"[Multi-vues] Global:\", len(views[\"global_time\"]), \"points\",\n",
    "          \"| Folded:\", \"ok\" if views[\"fold_phase\"] is not None else \"n/a\",\n",
    "          \"| Local:\", \"ok\" if views[\"local_phase\"] is not None else \"n/a\")\n",
    "    if has_period:\n",
    "        print(f\"[P={P:.6f} j | dur={dur*24:.2f} h | window ±{window_factor}×dur -> ±{(window_factor*dur/P):.4f} phase]\")\n",
    "        if single_like:\n",
    "            print(\"[Note] Cas 'single-transit-like' détecté: P possiblement mal contrainte.\")\n",
    "    else:\n",
    "        print(\"[Info] Aucune période fournie/détectée: seules les vues Globales sont produites.\")\n",
    "\n",
    "    return views\n",
    "\n",
    "# ---------- (Optionnel) mini-plot pour contrôle visuel ----------\n",
    "def plot_multires_views(views, title=\"\"):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,4))\n",
    "    # Global\n",
    "    axes[0].plot(views[\"global_time\"], views[\"global_flux\"], lw=1)\n",
    "    axes[0].set_title(\"Vue Globale\"); axes[0].set_xlabel(\"Temps (j)\"); axes[0].set_ylabel(\"Flux\")\n",
    "\n",
    "    # Folded\n",
    "    if views[\"fold_phase\"] is not None:\n",
    "        axes[1].plot(views[\"fold_phase\"], views[\"fold_flux\"], lw=1)\n",
    "    axes[1].set_title(\"Vue Pliée\"); axes[1].set_xlabel(\"Phase\"); axes[1].set_ylabel(\"Flux\")\n",
    "\n",
    "    # Local\n",
    "    if views[\"local_phase\"] is not None:\n",
    "        axes[2].plot(views[\"local_phase\"], views[\"local_flux\"], lw=1)\n",
    "    axes[2].set_title(\"Vue Locale\"); axes[2].set_xlabel(\"Phase\"); axes[2].set_ylabel(\"Flux\")\n",
    "    fig.suptitle(title)\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:27:32.485666Z",
     "iopub.status.busy": "2025-10-04T23:27:32.485157Z",
     "iopub.status.idle": "2025-10-04T23:27:33.076573Z",
     "shell.execute_reply": "2025-10-04T23:27:33.075900Z",
     "shell.execute_reply.started": "2025-10-04T23:27:32.485644Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=1.866987 j | dur=1.20 h | window ±2.0×dur -> ±0.0536 phase]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Suppose: proc existe déjà. Si bls_out existe aussi, on s'en sert pour P,t0,dur (sinon: vues globales seules).\n",
    "views = build_multires_views(proc, bls_out=globals().get(\"bls_out\", None),\n",
    "                             N_GLOBAL=2001, N_LOCAL=201, window_factor=2.0)\n",
    "\n",
    "# (optionnel) Visualisation rapide\n",
    "plot_multires_views(views, title=\"Multi-vues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (B) Extraction de features TSFRESH (baseline + fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:27:33.078072Z",
     "iopub.status.busy": "2025-10-04T23:27:33.077646Z",
     "iopub.status.idle": "2025-10-04T23:27:41.375886Z",
     "shell.execute_reply": "2025-10-04T23:27:41.375094Z",
     "shell.execute_reply.started": "2025-10-04T23:27:33.078049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Pipeline TSFRESH (extraction + sélection + normalisation) — Kaggle-ready\n",
    "# Hypothèses:\n",
    "#  - Vous avez déjà: df, cfg, infer_time_flux_columns(...), group_iter(...),\n",
    "#                    preprocess_single_lightcurve(...), run_bls_on_proc(...) (optionnel)\n",
    "#  - Objectif: produire un tableau de features par courbe (id de groupe),\n",
    "#              y ajouter des features astrophysiques (P, dur, depth, snr) si BLS dispo,\n",
    "#              puis sélectionner les top-K (optionnel, si y est fourni) et normaliser.\n",
    "# ============================================\n",
    "import numpy as np, pandas as pd, warnings, hashlib\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 0) Dépendances TSFRESH\n",
    "try:\n",
    "    from tsfresh.feature_extraction import extract_features, ComprehensiveFCParameters\n",
    "    from tsfresh.utilities.dataframe_functions import impute as tsfresh_impute\n",
    "    from tsfresh.feature_selection import select_features\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"TSFRESH manquant. Exécutez dans une cellule séparée: !pip -q install tsfresh\")\n",
    "\n",
    "# ---------- Utilitaires ----------\n",
    "def _gid_to_int(gid: str) -> int:\n",
    "    \"\"\"Mappe un identifiant texte de groupe vers un entier stable (pour TSFRESH 'id').\"\"\"\n",
    "    return int(hashlib.md5(gid.encode()).hexdigest()[:8], 16)\n",
    "\n",
    "def _make_long_df_from_proc(proc: dict, gid: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transforme la série uniformisée d'un groupe en format long pour TSFRESH:\n",
    "    colonnes: ['id','time','value']\n",
    "    \"\"\"\n",
    "    t = np.asarray(proc[\"time_uniform\"])\n",
    "    y = np.asarray(proc[\"flux_uniform\"])\n",
    "    m = np.isfinite(t) & np.isfinite(y)\n",
    "    df_long = pd.DataFrame({\n",
    "        \"id\": _gid_to_int(gid),\n",
    "        \"time\": t[m],\n",
    "        \"value\": y[m]\n",
    "    })\n",
    "    return df_long\n",
    "\n",
    "def _astrophys_extras_from_bls(bls_out: dict | None) -> dict:\n",
    "    \"\"\"\n",
    "    Extrait quelques indicateurs astrophysiques élémentaires depuis BLS (si dispo).\n",
    "    \"\"\"\n",
    "    extras = {\"P\": np.nan, \"duration\": np.nan, \"depth\": np.nan, \"snr_bls\": np.nan, \"single_transit_like\": np.nan}\n",
    "    if bls_out is None or \"results\" not in bls_out or len(bls_out[\"results\"]) == 0:\n",
    "        return extras\n",
    "    res0 = bls_out[\"results\"].iloc[0]\n",
    "    extras.update({\n",
    "        \"P\": float(res0.get(\"period\", np.nan)),\n",
    "        \"duration\": float(res0.get(\"duration\", np.nan)),          # jours\n",
    "        \"depth\": float(res0.get(\"depth\", np.nan)),\n",
    "        \"snr_bls\": float(res0.get(\"snr\", np.nan)),\n",
    "        \"single_transit_like\": float(bool(bls_out[\"periodogram\"].get(\"single_transit_like\", False)))\n",
    "    })\n",
    "    return extras\n",
    "\n",
    "# ---------- Extraction batched ----------\n",
    "def tsfresh_extract_for_groups(df: pd.DataFrame,\n",
    "                               cfg,\n",
    "                               time_col: str | None = None,\n",
    "                               flux_col: str | None = None,\n",
    "                               max_groups: int = 10,\n",
    "                               run_bls: bool = True,\n",
    "                               bls_params: dict | None = None) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    1) Boucle sur quelques groupes (id de cible), prétraite -> proc\n",
    "    2) Construit le long-DF pour TSFRESH et accumulateur de meta (astrophysique)\n",
    "    3) Extrait les features (~790) via ComprehensiveFCParameters\n",
    "    4) Retourne: (X_all, meta), indexé par id numérique (stable pour ce df)\n",
    "    \"\"\"\n",
    "    if time_col is None or flux_col is None:\n",
    "        time_col, flux_col = infer_time_flux_columns(df)\n",
    "\n",
    "    long_blocks = []\n",
    "    rows_meta = []\n",
    "\n",
    "    for i, (gid, sub) in enumerate(group_iter(df)):\n",
    "        if i >= max_groups:\n",
    "            break\n",
    "        sub = sub.sort_values(time_col)\n",
    "        proc = preprocess_single_lightcurve(sub, time_col, flux_col, cfg)\n",
    "\n",
    "        # BLS optionnel\n",
    "        bls_out = None\n",
    "        if run_bls:\n",
    "            try:\n",
    "                bp = bls_params or {}\n",
    "                # === AJOUT: calcule pmin/pmax pour cette série, puis borne les durées ===\n",
    "                t_uni = np.asarray(proc[\"time_uniform\"])\n",
    "                pmin, pmax, _ = estimate_period_bounds(\n",
    "                    t_uni,\n",
    "                    min_hours=bp.get(\"min_period_hours\", 7.0),\n",
    "                    max_frac_baseline=bp.get(\"max_period_frac_baseline\", 0.9)\n",
    "                )\n",
    "                dmin_h, dmax_h_req = bp.get(\"durations_hours\", (1.0, 12.0))\n",
    "                # contrainte Astropy: max(duration) < min(period)\n",
    "                dmax_h_safe = min(dmax_h_req, 0.8 * pmin * 24.0)  # 80% de P_min en heures\n",
    "                if not np.isfinite(dmax_h_safe) or dmax_h_safe <= dmin_h:\n",
    "                    dmax_h_safe = max(dmin_h + 0.25, dmin_h * 1.5)\n",
    "        \n",
    "                bls_out = run_bls_on_proc(\n",
    "                    proc,\n",
    "                    n_periods=bp.get(\"n_periods\", 5000),\n",
    "                    # on fixe min_period_hours d'après pmin estimé\n",
    "                    min_period_hours=24.0 * pmin,\n",
    "                    max_period_frac_baseline=bp.get(\"max_period_frac_baseline\", 0.9),\n",
    "                    durations_hours=(dmin_h, dmax_h_safe),\n",
    "                    n_durations=bp.get(\"n_durations\", 10),\n",
    "                    top_k=bp.get(\"top_k\", 3)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[BLS] Skip {gid}: {e}\")\n",
    "\n",
    "                \n",
    "        # Long-format pour TSFRESH\n",
    "        df_long = _make_long_df_from_proc(proc, gid)\n",
    "        long_blocks.append(df_long)\n",
    "\n",
    "        # 2) >>> ICI : construire les méta-infos à partir de BLS + infos neutres\n",
    "        extras = _astrophys_extras_from_bls(bls_out)\n",
    "        extras.update({\n",
    "            \"id\": _gid_to_int(gid),\n",
    "            \"gid\": gid,\n",
    "            # NOTE: preprocess_single_lightcurve ne renvoie pas 'resample_step_minutes' → on prend cfg\n",
    "            \"resample_step_minutes\": float(getattr(cfg, \"resample_step_minutes\", np.nan)),\n",
    "            \"n_points\": int(len(proc.get(\"time_uniform\", []))),\n",
    "            # (optionnel) provenance\n",
    "            \"period_source\": \"bls\" if bls_out is not None and len(bls_out.get(\"results\", [])) else \"none\",\n",
    "        })\n",
    "        rows_meta.append(extras)\n",
    "\n",
    "    if not long_blocks:\n",
    "        raise RuntimeError(\"Aucun groupe n'a été traité. Vérifiez vos données/paramètres.\")\n",
    "\n",
    "    long_df = pd.concat(long_blocks, ignore_index=True)\n",
    "    meta_df = pd.DataFrame(rows_meta).set_index(\"id\").sort_index()\n",
    "\n",
    "    # TSFRESH extraction (Comprehensive)\n",
    "    settings = ComprehensiveFCParameters()\n",
    "    # NOTE: vous pouvez réduire la charge en supprimant des familles de features dans 'settings'\n",
    "    X = extract_features(\n",
    "        long_df,\n",
    "        column_id=\"id\",\n",
    "        column_sort=\"time\",\n",
    "        column_value=\"value\",\n",
    "        default_fc_parameters=settings,\n",
    "        disable_progressbar=True,\n",
    "        n_jobs=0  # 0 => séquentiel (plus sûr sur petits kernels)\n",
    "    )\n",
    "\n",
    "    # Imputation TSFRESH (remplit NaN/Inf de manière standard)\n",
    "    tsfresh_impute(X)\n",
    "\n",
    "    # Concat meta/astro\n",
    "    for col in meta_df.columns:\n",
    "        X[col] = meta_df[col].reindex(X.index)\n",
    "\n",
    "    # Index = id numérique, gardons aussi la colonne texte 'gid' pour traçabilité\n",
    "    # (déjà incluse ci-dessus via meta_df[\"gid\"])\n",
    "    return X, meta_df\n",
    "\n",
    "# ---------- Sélection supervisée (optionnelle) ----------\n",
    "def tsfresh_supervised_selection(X: pd.DataFrame, y: pd.Series | pd.DataFrame,\n",
    "                                 fdr_level: float = 0.05, top_k: int | None = 100) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    y: Series indexée par 'id' (entier) avec labels 0/1 ou multi-classes.\n",
    "    - Applique la sélection TSFRESH (tests d'hypothèse + contrôle FDR).\n",
    "    - Si top_k est spécifié, garde les K meilleures (par p-value croissante).\n",
    "    \"\"\"\n",
    "    # Harmonise les index\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        if y.shape[1] != 1:\n",
    "            raise ValueError(\"y DataFrame doit avoir une seule colonne (label).\")\n",
    "        y = y.iloc[:, 0]\n",
    "    y = y.reindex(X.index)\n",
    "\n",
    "    X_sel = select_features(X.drop(columns=[\"gid\"], errors=\"ignore\"), y, fdr_level=fdr_level)\n",
    "    # Ré-attacher 'gid' pour info\n",
    "    if \"gid\" in X.columns:\n",
    "        X_sel[\"gid\"] = X[\"gid\"]\n",
    "\n",
    "    if top_k is not None and X_sel.shape[1] > top_k + (1 if \"gid\" in X_sel.columns else 0):\n",
    "        # Ordre par variance (proxy simple) si p-values non accessibles ici\n",
    "        non_meta_cols = [c for c in X_all.columns if c not in (\"gid\",)]\n",
    "        var_order = X_all[non_meta_cols].var().sort_values(ascending=False).index.tolist()[:top_k]\n",
    "        keep = var_order[:top_k]\n",
    "        X_sel = X_sel[keep + ([\"gid\"] if \"gid\" in X_sel.columns else [])]\n",
    "\n",
    "    return X_sel\n",
    "\n",
    "# ---------- Normalisation robuste (pour entrée MLP d'embedding) ----------\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def normalize_tsfresh_features(X_sel: pd.DataFrame) -> tuple[np.ndarray, list[str], RobustScaler]:\n",
    "    \"\"\"\n",
    "    Retire 'gid' si présent, fit un RobustScaler, renvoie (X_norm, feature_names, scaler).\n",
    "    \"\"\"\n",
    "    cols = [c for c in X_sel.columns if c != \"gid\"]\n",
    "    scaler = RobustScaler()\n",
    "    X_norm = scaler.fit_transform(X_sel[cols].values.astype(float))\n",
    "    return X_norm, cols, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:27:41.378678Z",
     "iopub.status.busy": "2025-10-04T23:27:41.378100Z",
     "iopub.status.idle": "2025-10-04T23:30:04.881238Z",
     "shell.execute_reply": "2025-10-04T23:30:04.880479Z",
     "shell.execute_reply.started": "2025-10-04T23:27:41.378654Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TSFRESH] Matrice brute: (5, 792) | colonnes (extrait): ['value__variance_larger_than_standard_deviation', 'value__has_duplicate_max', 'value__has_duplicate_min', 'value__has_duplicate', 'value__sum_values', 'value__abs_energy', 'value__mean_abs_change', 'value__mean_change']\n",
      "[TSFRESH] Meta (index=id):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>duration</th>\n",
       "      <th>depth</th>\n",
       "      <th>snr_bls</th>\n",
       "      <th>single_transit_like</th>\n",
       "      <th>gid</th>\n",
       "      <th>resample_step_minutes</th>\n",
       "      <th>n_points</th>\n",
       "      <th>period_source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1054784497</th>\n",
       "      <td>14.306780</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>10.044530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>target_id=TIC_238597883</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3947</td>\n",
       "      <td>bls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511118701</th>\n",
       "      <td>13.061843</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.031464</td>\n",
       "      <td>11.176657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>target_id=TIC_50365310</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3947</td>\n",
       "      <td>bls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632108578</th>\n",
       "      <td>1.866987</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>13.629291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>target_id=TIC_124709665</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3947</td>\n",
       "      <td>bls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657826233</th>\n",
       "      <td>12.977151</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.016172</td>\n",
       "      <td>11.590027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>target_id=TIC_106997505</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3947</td>\n",
       "      <td>bls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192431990</th>\n",
       "      <td>1.931449</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>-0.118984</td>\n",
       "      <td>18.336506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>target_id=TIC_88863718</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3947</td>\n",
       "      <td>bls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    P  duration     depth    snr_bls  single_transit_like  \\\n",
       "id                                                                          \n",
       "1054784497  14.306780  0.233333  0.005111  10.044530                  0.0   \n",
       "1511118701  13.061843  0.233333  0.031464  11.176657                  0.0   \n",
       "1632108578   1.866987  0.050000  0.000949  13.629291                  0.0   \n",
       "1657826233  12.977151  0.233333  0.016172  11.590027                  0.0   \n",
       "2192431990   1.931449  0.108333 -0.118984  18.336506                  0.0   \n",
       "\n",
       "                                gid  resample_step_minutes  n_points  \\\n",
       "id                                                                     \n",
       "1054784497  target_id=TIC_238597883                   10.0      3947   \n",
       "1511118701   target_id=TIC_50365310                   10.0      3947   \n",
       "1632108578  target_id=TIC_124709665                   10.0      3947   \n",
       "1657826233  target_id=TIC_106997505                   10.0      3947   \n",
       "2192431990   target_id=TIC_88863718                   10.0      3947   \n",
       "\n",
       "           period_source  \n",
       "id                        \n",
       "1054784497           bls  \n",
       "1511118701           bls  \n",
       "1632108578           bls  \n",
       "1657826233           bls  \n",
       "2192431990           bls  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TSFRESH] Sélection non supervisée ~ top-100 par variance: (5, 101)\n",
      "[TSFRESH] X_norm prêt pour MLP d'embedding: (5, 100)\n"
     ]
    }
   ],
   "source": [
    "# ---------- EXEMPLE D’USAGE (extrait, mêmes variables) ----------\n",
    "# 1) détecter colonnes time/flux\n",
    "time_col, flux_col = infer_time_flux_columns(df)\n",
    "\n",
    "# 2) extraire features tsfresh (sur quelques groupes pour démo)\n",
    "X_all, meta = tsfresh_extract_for_groups(\n",
    "    df, cfg, time_col=time_col, flux_col=flux_col,\n",
    "    max_groups=5, run_bls=True,\n",
    "    bls_params=dict(min_period_hours=7.0, max_period_frac_baseline=0.9,\n",
    "                    durations_hours=(1.0, 12.0), n_durations=10, top_k=3)\n",
    ")\n",
    "print(\"[TSFRESH] Matrice brute:\", X_all.shape, \"| colonnes (extrait):\", X_all.columns[:8].tolist())\n",
    "print(\"[TSFRESH] Meta (index=id):\")\n",
    "display(meta.head())\n",
    "\n",
    "# 3) (optionnel) si vous avez des labels par id (Series y: index=id -> {0,1})\n",
    "# y = ...  # e.g., pd.Series(..., index=X_all.index)\n",
    "# X_sel = tsfresh_supervised_selection(X_all, y, fdr_level=0.05, top_k=100)\n",
    "# print(\"[TSFRESH] Sélection supervisée:\", X_sel.shape)\n",
    "\n",
    "# Si pas de labels pour le moment, prenez un sous-ensemble de features par variance:\n",
    "num_cols = [\n",
    "    c for c in X_all.columns\n",
    "    if c != \"gid\" and pd.api.types.is_numeric_dtype(X_all[c])\n",
    "]\n",
    "\n",
    "# Sécuriser la conversion si des colonnes sont object/mixte\n",
    "X_num = X_all[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "top_k = 100 if len(num_cols) > 100 else len(num_cols)\n",
    "var_order = X_num.var(numeric_only=True).sort_values(ascending=False).index.tolist()[:top_k]\n",
    "\n",
    "# Reconstruire X_sel et ré-attacher 'gid' pour traçabilité\n",
    "X_sel = X_num[var_order]\n",
    "if \"gid\" in X_all.columns:\n",
    "    X_sel = pd.concat([X_sel, X_all[[\"gid\"]]], axis=1)\n",
    "\n",
    "print(f\"[TSFRESH] Sélection non supervisée ~ top-{top_k} par variance:\", X_sel.shape)\n",
    "\n",
    "# 4) Normalisation robuste pour l'entrée du MLP d'embedding (section fusion tardive)\n",
    "X_norm, feat_names, scaler = normalize_tsfresh_features(X_sel)\n",
    "print(\"[TSFRESH] X_norm prêt pour MLP d'embedding:\", X_norm.shape)\n",
    "\n",
    "# (Optionnel) Sauvegardes pour la suite (Transformer + fusion tardive)\n",
    "# X_all.to_parquet(\"tsfresh_all.parquet\")\n",
    "# X_sel.to_parquet(\"tsfresh_selected.parquet\")\n",
    "# with open(\"tsfresh_scaler.pkl\", \"wb\") as f:\n",
    "#     import pickle; pickle.dump(scaler, f)\n",
    "\n",
    "# NOTE Fusion tardive (implémentation à venir dans la section C):\n",
    "#  - Dans votre modèle, créez un petit MLP (ex: Dense 256, dropout) qui prend X_norm (K features)\n",
    "#    et produit un embedding (par ex. shape [batch, 256]).\n",
    "#  - Concaténez cet embedding avec le token [CLS] (ou le pooling global) du Transformer\n",
    "#    avant la tête de classification finale. Pensez à régulariser (dropout/L2) la branche tabulaire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (C) Transformer multi-vues enrichi de connaissances physiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:30:04.882368Z",
     "iopub.status.busy": "2025-10-04T23:30:04.882083Z",
     "iopub.status.idle": "2025-10-04T23:30:08.465597Z",
     "shell.execute_reply": "2025-10-04T23:30:08.465004Z",
     "shell.execute_reply.started": "2025-10-04T23:30:04.882338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# (C) Transformer multi-vues enrichi — Kaggle-ready (PyTorch)\n",
    "# Hypothèses:\n",
    "#  - Vous avez déjà: `views` (depuis build_multires_views) avec:\n",
    "#      views[\"global_time\"], views[\"global_flux\"]  (N_GLOBAL=2001 par défaut)\n",
    "#      views[\"local_phase\"], views[\"local_flux\"]  (N_LOCAL=201   par défaut)  # peut être None si pas de P\n",
    "#      views[\"meta\"] = {\"P\",\"t0\",\"dur\",\"has_period\", ...}\n",
    "#  - Optionnel: X_norm (features TSFRESH normalisées) si vous avez exécuté la partie TSFRESH.\n",
    "#    Vous pouvez passer un vecteur tabulaire au forward pour la fusion tardive.\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Construction de la séquence concaténée (Global + [SEP] + Locale pliée)\n",
    "# -----------------------------\n",
    "def build_concat_sequence_from_views(views, add_sep_token=True):\n",
    "    \"\"\"\n",
    "    Concatène la vue globale (time, flux) et la vue locale pliée (phase, flux)\n",
    "    en une seule séquence, avec:\n",
    "      - un token [CLS] en tête\n",
    "      - optionnellement un token [SEP] entre global et local\n",
    "      - un segment_id (0 pour global, 1 pour local, 2 pour [CLS]/[SEP])\n",
    "\n",
    "    Sortie: dict numpy avec\n",
    "      seq_flux         : (L,) flux normalisé (global puis local)\n",
    "      pos_time_global  : (L,) position absolue/relative global (0..1) sinon 0 pour tokens non-globaux\n",
    "      pos_phase_local  : (L,) phase repliee (-0.5..0.5) sinon 0 pour tokens non-locaux\n",
    "      delta            : (L,) delta-temps (global) / delta-phase (local), 0 aux bornes et tokens spéciaux\n",
    "      segment_id       : (L,) {0=global, 1=local, 2=special}\n",
    "      attn_mask        : (L,) 1=valide, 0=padding (pas de padding ici)\n",
    "      special_mask     : (L,) 1 si [CLS] ou [SEP]\n",
    "    \"\"\"\n",
    "    # Global\n",
    "    gt, gf = np.asarray(views[\"global_time\"]), np.asarray(views[\"global_flux\"])\n",
    "    assert gt.shape == gf.shape and gt.ndim == 1\n",
    "    Lg = len(gf)\n",
    "\n",
    "    # Local (peut être None si pas de P)\n",
    "    lp, lf = views.get(\"local_phase\", None), views.get(\"local_flux\", None)\n",
    "    has_local = (lp is not None) and (lf is not None)\n",
    "    if has_local:\n",
    "        lp, lf = np.asarray(lp), np.asarray(lf)\n",
    "        assert lp.shape == lf.shape and lp.ndim == 1\n",
    "        Ll = len(lf)\n",
    "    else:\n",
    "        Ll = 0\n",
    "\n",
    "    # Corps séquence sans specials\n",
    "    seq_flux = np.concatenate([gf, lf]) if has_local else gf\n",
    "\n",
    "    # Encodage positionnel global (0..1) pour la partie globale\n",
    "    if Lg > 1:\n",
    "        pos_time_global = (gt - gt.min()) / max(1e-12, (gt.max() - gt.min()))\n",
    "    else:\n",
    "        pos_time_global = np.zeros_like(gt)\n",
    "    pos_time_global_full = np.concatenate([pos_time_global, np.zeros(Ll)]) if has_local else pos_time_global\n",
    "\n",
    "    # Encodage positionnel local (phase -0.5..0.5) pour la partie locale\n",
    "    pos_phase_local_full = np.concatenate([np.zeros(Lg), lp]) if has_local else np.zeros(Lg)\n",
    "\n",
    "    # Delta (global: Δt normalisé; local: Δphase)\n",
    "    delta_g = np.zeros(Lg)\n",
    "    if Lg > 1:\n",
    "        dt = np.diff(gt)\n",
    "        # normaliser par médiane des Δt pour l'échelle\n",
    "        med = np.median(dt[~np.isnan(dt)]) if np.isfinite(dt).any() else 1.0\n",
    "        med = med if med > 0 else 1.0\n",
    "        delta_g[1:] = dt / med\n",
    "        delta_g[~np.isfinite(delta_g)] = 0.0\n",
    "\n",
    "    if has_local:\n",
    "        delta_l = np.zeros(Ll)\n",
    "        if Ll > 1:\n",
    "            dph = np.diff(lp)\n",
    "            medp = np.median(dph[~np.isnan(dph)]) if np.isfinite(dph).any() else 1.0\n",
    "            medp = medp if medp != 0 else 1.0\n",
    "            delta_l[1:] = dph / medp\n",
    "            delta_l[~np.isfinite(delta_l)] = 0.0\n",
    "        delta_full = np.concatenate([delta_g, delta_l])\n",
    "    else:\n",
    "        delta_full = delta_g\n",
    "\n",
    "    # Segment IDs (0=global, 1=local)\n",
    "    segment_id = np.concatenate([np.zeros(Lg, dtype=np.int64),\n",
    "                                 np.ones(Ll, dtype=np.int64)]) if has_local else np.zeros(Lg, dtype=np.int64)\n",
    "\n",
    "    # Ajout des specials [CLS] (+ [SEP] si local)\n",
    "    specials = 1 + int(add_sep_token and has_local)\n",
    "    L = len(seq_flux) + 1 + (1 if (add_sep_token and has_local) else 0)\n",
    "\n",
    "    seq_flux_w = np.empty(L, dtype=np.float32)\n",
    "    pos_time_w = np.zeros(L, dtype=np.float32)\n",
    "    pos_phase_w = np.zeros(L, dtype=np.float32)\n",
    "    delta_w    = np.zeros(L, dtype=np.float32)\n",
    "    segment_w  = np.full(L, 2, dtype=np.int64)  # 2 pour specials par défaut\n",
    "    attn_mask  = np.ones(L, dtype=np.int64)\n",
    "    special_m  = np.zeros(L, dtype=np.int64)\n",
    "\n",
    "    # [CLS] en tête\n",
    "    i = 0\n",
    "    seq_flux_w[i] = 0.0\n",
    "    special_m[i]  = 1\n",
    "    # partie globale\n",
    "    seq_flux_w[i+1 : i+1+Lg] = seq_flux[:Lg]\n",
    "    pos_time_w [i+1 : i+1+Lg] = pos_time_global_full[:Lg]\n",
    "    pos_phase_w[i+1 : i+1+Lg] = 0.0\n",
    "    delta_w    [i+1 : i+1+Lg] = delta_full[:Lg]\n",
    "    segment_w  [i+1 : i+1+Lg] = 0  # global\n",
    "    cur = i + 1 + Lg\n",
    "\n",
    "    if has_local:\n",
    "        if add_sep_token:\n",
    "            # [SEP]\n",
    "            seq_flux_w[cur] = 0.0\n",
    "            special_m[cur]  = 1\n",
    "            segment_w [cur] = 2\n",
    "            cur += 1\n",
    "        # partie locale\n",
    "        seq_flux_w[cur : cur+Ll] = seq_flux[Lg:]\n",
    "        pos_time_w [cur : cur+Ll] = 0.0\n",
    "        pos_phase_w[cur : cur+Ll] = pos_phase_local_full[Lg:]\n",
    "        delta_w    [cur : cur+Ll] = delta_full[Lg:]\n",
    "        segment_w  [cur : cur+Ll] = 1  # local\n",
    "\n",
    "    return {\n",
    "        \"seq_flux\": seq_flux_w.astype(np.float32),\n",
    "        \"pos_time\": pos_time_w.astype(np.float32),\n",
    "        \"pos_phase\": pos_phase_w.astype(np.float32),\n",
    "        \"delta\": delta_w.astype(np.float32),\n",
    "        \"segment_id\": segment_w.astype(np.int64),\n",
    "        \"attn_mask\": attn_mask.astype(np.int64),\n",
    "        \"special_mask\": special_m.astype(np.int64)\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Modèle Transformer multi-vues avec encodages physiques + fusion TSFRESH\n",
    "# -----------------------------\n",
    "class MultiViewTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model=256,\n",
    "                 nhead=8,\n",
    "                 num_layers=4,\n",
    "                 dim_feedforward=512,\n",
    "                 dropout=0.1,\n",
    "                 # encodages d'entrée\n",
    "                 use_delta=True,\n",
    "                 # embeddings\n",
    "                 segment_vocab_size=3,     # 0=global,1=local,2=special\n",
    "                 # fusion tabulaire (TSFRESH)\n",
    "                 tabular_dim: int | None = None,   # dimension d'entrée tabulaire (K)\n",
    "                 tabular_hidden: int = 256,        # taille MLP d'embedding TSFRESH\n",
    "                 n_classes=2):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.use_delta = use_delta\n",
    "\n",
    "        # Projette les features scalaires d'entrée vers d_model\n",
    "        in_dim = 1 + 1 + 1 + (1 if use_delta else 0)  # flux + pos_time + pos_phase + delta (option)\n",
    "        self.value_proj = nn.Linear(in_dim, d_model)\n",
    "\n",
    "        # Embedding de segment (global/local/special)\n",
    "        self.segment_embed = nn.Embedding(segment_vocab_size, d_model)\n",
    "\n",
    "        # (Option) petit encodeur MLP pour combiner value_proj + segment_embed\n",
    "        self.input_ln = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout, batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Token [CLS] => on prendra l'index 0\n",
    "        # Tête de classification basée sur [CLS], avec fusion optionnelle TSFRESH\n",
    "        if tabular_dim is not None and tabular_dim > 0:\n",
    "            self.tabular_mlp = nn.Sequential(\n",
    "                nn.Linear(tabular_dim, tabular_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(tabular_hidden, tabular_hidden),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            self.cls_head = nn.Sequential(\n",
    "                nn.LayerNorm(d_model + tabular_hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(d_model + tabular_hidden, n_classes)\n",
    "            )\n",
    "        else:\n",
    "            self.tabular_mlp = None\n",
    "            self.cls_head = nn.Sequential(\n",
    "                nn.LayerNorm(d_model),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(d_model, n_classes)\n",
    "            )\n",
    "\n",
    "    def forward(self, batch, tabular=None):\n",
    "        \"\"\"\n",
    "        batch: dict de tensors (B,L)\n",
    "          - seq_flux, pos_time, pos_phase, delta, segment_id, attn_mask\n",
    "        tabular: (B, K) ou None — vecteur TSFRESH normalisé\n",
    "        \"\"\"\n",
    "        x_parts = [batch[\"seq_flux\"].unsqueeze(-1),\n",
    "                   batch[\"pos_time\"].unsqueeze(-1),\n",
    "                   batch[\"pos_phase\"].unsqueeze(-1)]\n",
    "        if self.use_delta:\n",
    "            x_parts.append(batch[\"delta\"].unsqueeze(-1))\n",
    "        x = torch.cat(x_parts, dim=-1)  # (B, L, in_dim)\n",
    "\n",
    "        h = self.value_proj(x) + self.segment_embed(batch[\"segment_id\"])\n",
    "        h = self.input_ln(h)\n",
    "\n",
    "        # Attention mask: True pour les positions à masquer -> on inverse\n",
    "        # Ici pas de padding, mais on autorise quand même special_mask=1 comme positions normales\n",
    "        src_key_padding_mask = (batch[\"attn_mask\"] == 0)  # (B, L) bool\n",
    "        z = self.encoder(h, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # [CLS] = position 0\n",
    "        cls = z[:, 0, :]  # (B, d_model)\n",
    "\n",
    "        if self.tabular_mlp is not None and tabular is not None:\n",
    "            t_emb = self.tabular_mlp(tabular)\n",
    "            cls = torch.cat([cls, t_emb], dim=-1)\n",
    "\n",
    "        logits = self.cls_head(cls)\n",
    "        return logits\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Collate d'un seul exemple (ou mini-batch) depuis `views` (+ tabulaire optionnel)\n",
    "# -----------------------------\n",
    "def make_batch_from_views(views_list, X_tsfresh_norm=None, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    views_list : liste de dicts `views` (taille B)\n",
    "    X_tsfresh_norm : None ou np.ndarray (B, K) (features déjà normalisées)\n",
    "    Retourne: (batch_dict_tensors, tabular_tensor_or_None)\n",
    "    \"\"\"\n",
    "    seqs = [build_concat_sequence_from_views(v, add_sep_token=True) for v in views_list]\n",
    "\n",
    "    def to_tensor(key, dtype=torch.float32):\n",
    "        arrs = [s[key] for s in seqs]\n",
    "        t = torch.tensor(np.stack(arrs, axis=0), dtype=dtype, device=device)\n",
    "        return t\n",
    "\n",
    "    batch = {\n",
    "        \"seq_flux\":  to_tensor(\"seq_flux\",  torch.float32),\n",
    "        \"pos_time\":  to_tensor(\"pos_time\",  torch.float32),\n",
    "        \"pos_phase\": to_tensor(\"pos_phase\", torch.float32),\n",
    "        \"delta\":     to_tensor(\"delta\",     torch.float32),\n",
    "        \"segment_id\":to_tensor(\"segment_id\",torch.long),\n",
    "        \"attn_mask\": to_tensor(\"attn_mask\", torch.long),\n",
    "        \"special_mask\": to_tensor(\"special_mask\", torch.long),\n",
    "    }\n",
    "\n",
    "    tab = None\n",
    "    if X_tsfresh_norm is not None:\n",
    "        tab = torch.tensor(np.asarray(X_tsfresh_norm), dtype=torch.float32, device=device)\n",
    "    return batch, tab\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:30:08.466811Z",
     "iopub.status.busy": "2025-10-04T23:30:08.466356Z",
     "iopub.status.idle": "2025-10-04T23:30:11.444682Z",
     "shell.execute_reply": "2025-10-04T23:30:11.443926Z",
     "shell.execute_reply.started": "2025-10-04T23:30:08.466793Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Transformer] logits shape: (1, 2)\n",
      "[Transformer] logits (extrait): [0.252063   0.23923135]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4) Démo rapide avec l'exemple courant\n",
    "# -----------------------------\n",
    "# Crée un batch à partir d'une seule courbe (views) — ajoutez-en d'autres courbes si vous voulez un batch > 1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch, tab = make_batch_from_views([views], X_tsfresh_norm=None, device=device)\n",
    "\n",
    "# Instancie le modèle (sans TSFRESH pour l’instant). \n",
    "# Si vous avez K features TSFRESH normalisées dans `tab`, passez tabular_dim=K et `tab` au forward.\n",
    "model = MultiViewTransformer(\n",
    "    d_model=256, nhead=8, num_layers=4, dim_feedforward=512, dropout=0.1,\n",
    "    use_delta=True,\n",
    "    segment_vocab_size=3,\n",
    "    tabular_dim=(tab.shape[1] if tab is not None else None),\n",
    "    tabular_hidden=256,\n",
    "    n_classes=2\n",
    ").to(device)\n",
    "\n",
    "# Passage avant (logits)\n",
    "with torch.no_grad():\n",
    "    logits = model(batch, tabular=tab)   # shape (B, n_classes)\n",
    "print(\"[Transformer] logits shape:\", tuple(logits.shape))\n",
    "print(\"[Transformer] logits (extrait):\", logits[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens spéciaux [STAR] et [PHYS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:30:11.446008Z",
     "iopub.status.busy": "2025-10-04T23:30:11.445594Z",
     "iopub.status.idle": "2025-10-04T23:30:11.481789Z",
     "shell.execute_reply": "2025-10-04T23:30:11.481123Z",
     "shell.execute_reply.started": "2025-10-04T23:30:11.445991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Tokens spéciaux [STAR] et [PHYS] pour le Transformer multi-vues\n",
    "# — même logique/variables, compatible avec `views` et (optionnel) `bls_out`\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Features des tokens [STAR] et [PHYS]\n",
    "# -----------------------------\n",
    "def build_star_phys_features(views: dict,\n",
    "                             star_info: dict | None = None,\n",
    "                             bls_out: dict | None = None):\n",
    "    \"\"\"\n",
    "    Construit STAR (6) et PHYS (5) en gérant les types non-numériques (str, arrays, None).\n",
    "    STAR ordre: [teff_K, radius_Rsun, mass_Msun, mag, ra_deg, dec_deg]\n",
    "    PHYS ordre: [P_days, dur_days, depth, snr_bls, single_flag]\n",
    "    \"\"\"\n",
    "\n",
    "    def to_float(x):\n",
    "        \"\"\"Convertit x en float; retourne np.nan si impossible.\"\"\"\n",
    "        try:\n",
    "            if x is None:\n",
    "                return np.nan\n",
    "            # si c'est un array/série avec 1 élément\n",
    "            if hasattr(x, \"__len__\") and not isinstance(x, (str, bytes)):\n",
    "                arr = np.asarray(x)\n",
    "                if arr.size == 0:\n",
    "                    return np.nan\n",
    "                return float(arr.reshape(-1)[0])\n",
    "            return float(x)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    # ---- STAR ----\n",
    "    star_defaults = dict(teff_K=np.nan, radius_Rsun=np.nan, mass_Msun=np.nan,\n",
    "                         mag=np.nan, ra_deg=np.nan, dec_deg=np.nan)\n",
    "    if star_info is not None:\n",
    "        for k in star_defaults:\n",
    "            star_defaults[k] = to_float(star_info.get(k, np.nan))\n",
    "\n",
    "    sv = np.array([\n",
    "        star_defaults[\"teff_K\"],\n",
    "        star_defaults[\"radius_Rsun\"],\n",
    "        star_defaults[\"mass_MSun\"] if \"mass_MSun\" in star_defaults else star_defaults[\"mass_Msun\"],\n",
    "        star_defaults[\"mag\"],\n",
    "        star_defaults[\"ra_deg\"],\n",
    "        star_defaults[\"dec_deg\"],\n",
    "    ], dtype=float)\n",
    "\n",
    "    # normalisation simple\n",
    "    def _safe_log1p_pos(x):\n",
    "        x = to_float(x)\n",
    "        return np.log1p(x) if (np.isfinite(x) and x > 0) else 0.0\n",
    "\n",
    "    sv_norm = np.array([\n",
    "        _safe_log1p_pos(sv[0]),                       # teff\n",
    "        _safe_log1p_pos(sv[1]),                       # radius\n",
    "        _safe_log1p_pos(sv[2]),                       # mass\n",
    "        0.1 * (sv[3] - 10.0) if np.isfinite(sv[3]) else 0.0,   # mag\n",
    "        (sv[4] / 180.0) if np.isfinite(sv[4]) else 0.0,        # ra\n",
    "        (sv[5] / 90.0)  if np.isfinite(sv[5]) else 0.0,        # dec\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    # ---- PHYS ----\n",
    "    # récupère d'abord depuis views.meta\n",
    "    P = to_float(views.get(\"meta\", {}).get(\"P\", np.nan))\n",
    "    dur = to_float(views.get(\"meta\", {}).get(\"dur\", np.nan))\n",
    "    depth = to_float(views.get(\"meta\", {}).get(\"depth\", np.nan))\n",
    "    snr = to_float(views.get(\"meta\", {}).get(\"snr_bls\", np.nan))\n",
    "    single_flag = float(1.0 if views.get(\"meta\", {}).get(\"single_transit_like\", False) else 0.0)\n",
    "\n",
    "    # écrase par BLS si dispo\n",
    "    if bls_out is not None and \"results\" in bls_out and len(bls_out[\"results\"]) > 0:\n",
    "        best = bls_out[\"results\"].iloc[0]\n",
    "        P_b   = to_float(best.get(\"period\", np.nan))\n",
    "        dur_b = to_float(best.get(\"duration\", np.nan))\n",
    "        depth_b = to_float(best.get(\"depth\", np.nan))\n",
    "        snr_b   = to_float(best.get(\"snr\", np.nan))\n",
    "        if np.isfinite(P_b):   P = P_b\n",
    "        if np.isfinite(dur_b): dur = dur_b\n",
    "        if np.isfinite(depth_b): depth = depth_b\n",
    "        if np.isfinite(snr_b):   snr = snr_b\n",
    "        single_flag = float(1.0 if bls_out.get(\"periodogram\", {}).get(\"single_transit_like\", False) else single_flag)\n",
    "\n",
    "    # mise à l'échelle\n",
    "    pv_norm = np.array([\n",
    "        np.log1p(P)   if (np.isfinite(P)   and P   > 0) else 0.0,  # logP\n",
    "        np.log1p(dur) if (np.isfinite(dur) and dur > 0) else 0.0,  # log dur\n",
    "        1e3 * depth   if (np.isfinite(depth)) else 0.0,            # depth -> milli\n",
    "        np.tanh(0.1 * snr) if np.isfinite(snr) else 0.0,           # snr compacté\n",
    "        single_flag,\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    # nettoie NaN résiduels\n",
    "    sv_norm[~np.isfinite(sv_norm)] = 0.0\n",
    "    pv_norm[~np.isfinite(pv_norm)] = 0.0\n",
    "\n",
    "    return sv_norm.astype(np.float32), pv_norm.astype(np.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Séquence concaténée avec [CLS], [STAR], [PHYS], Global, [SEP], Local\n",
    "# -----------------------------\n",
    "def build_concat_sequence_with_star_phys(views, star_vec, phys_vec, add_sep_token=True):\n",
    "    \"\"\"\n",
    "    Identique à `build_concat_sequence_from_views`, mais on préfixe deux tokens:\n",
    "    [CLS] (appris), [STAR] (porteur des méta stellaires), [PHYS] (porteur des params/priors transit).\n",
    "    Les buffers scalaires (flux/pos/delta/segment) des tokens spéciaux restent à 0,\n",
    "    ils seront remplacés par des embeddings dédiés dans le modèle.\n",
    "    \"\"\"\n",
    "    # --- séquences data (global/local) comme avant ---\n",
    "    gt, gf = np.asarray(views[\"global_time\"]), np.asarray(views[\"global_flux\"])\n",
    "    Lg = len(gf)\n",
    "    lp, lf = views.get(\"local_phase\", None), views.get(\"local_flux\", None)\n",
    "    has_local = (lp is not None) and (lf is not None)\n",
    "    if has_local: \n",
    "        lp, lf = np.asarray(lp), np.asarray(lf)\n",
    "        Ll = len(lf)\n",
    "    else:\n",
    "        Ll = 0\n",
    "\n",
    "    # pos encodings\n",
    "    if Lg > 1:\n",
    "        pos_time_global = (gt - gt.min()) / max(1e-12, (gt.max() - gt.min()))\n",
    "    else:\n",
    "        pos_time_global = np.zeros_like(gt)\n",
    "    pos_phase_local = np.zeros(Lg) if not has_local else np.concatenate([np.zeros(Lg), lp])\n",
    "\n",
    "    # deltas\n",
    "    delta_g = np.zeros(Lg)\n",
    "    if Lg > 1:\n",
    "        dt = np.diff(gt); med = np.median(dt[~np.isnan(dt)]) if np.isfinite(dt).any() else 1.0\n",
    "        med = med if med > 0 else 1.0\n",
    "        delta_g[1:] = dt / med\n",
    "    delta_full = np.concatenate([delta_g, np.zeros(Ll) if not has_local else np.r_[0, np.diff(lp) / (np.median(np.diff(lp)) if Ll > 1 else 1.0)]]) if has_local else delta_g\n",
    "    delta_full[~np.isfinite(delta_full)] = 0.0\n",
    "\n",
    "    # concat data-only\n",
    "    seq_flux = np.concatenate([gf, lf]) if has_local else gf\n",
    "    pos_time_full = np.concatenate([pos_time_global, np.zeros(Ll)]) if has_local else pos_time_global\n",
    "\n",
    "    # segments (0=global, 1=local, 2=special)\n",
    "    segment_full = np.concatenate([np.zeros(Lg, dtype=np.int64),\n",
    "                                   np.ones(Ll, dtype=np.int64)]) if has_local else np.zeros(Lg, dtype=np.int64)\n",
    "\n",
    "    # --- ajouter specials: [CLS], [STAR], [PHYS] (+ [SEP] si local) ---\n",
    "    extra = 3 + (1 if (add_sep_token and has_local) else 0)\n",
    "    L = len(seq_flux) + extra\n",
    "\n",
    "    seq_flux_w = np.zeros(L, dtype=np.float32)\n",
    "    pos_time_w = np.zeros(L, dtype=np.float32)\n",
    "    pos_phase_w = np.zeros(L, dtype=np.float32)\n",
    "    delta_w    = np.zeros(L, dtype=np.float32)\n",
    "    segment_w  = np.full(L, 2, dtype=np.int64)  # specials => 2\n",
    "    attn_mask  = np.ones(L, dtype=np.int64)\n",
    "    special_m  = np.zeros(L, dtype=np.int64)\n",
    "\n",
    "    # indices\n",
    "    i = 0                      # [CLS]\n",
    "    special_m[i] = 1\n",
    "    i_star = 1                 # [STAR]\n",
    "    special_m[i_star] = 1\n",
    "    i_phys = 2                 # [PHYS]\n",
    "    special_m[i_phys] = 1\n",
    "\n",
    "    cur = 3\n",
    "    # global\n",
    "    seq_flux_w[cur:cur+Lg] = seq_flux[:Lg]\n",
    "    pos_time_w[cur:cur+Lg] = pos_time_full[:Lg]\n",
    "    pos_phase_w[cur:cur+Lg] = 0.0\n",
    "    delta_w[cur:cur+Lg] = delta_full[:Lg]\n",
    "    segment_w[cur:cur+Lg] = 0\n",
    "    cur += Lg\n",
    "\n",
    "    if has_local:\n",
    "        if add_sep_token:\n",
    "            special_m[cur] = 1  # [SEP]\n",
    "            segment_w[cur] = 2\n",
    "            cur += 1\n",
    "        # local\n",
    "        seq_flux_w[cur:cur+Ll] = seq_flux[Lg:]\n",
    "        pos_time_w[cur:cur+Ll] = 0.0\n",
    "        pos_phase_w[cur:cur+Ll] = pos_phase_local[Lg:]\n",
    "        delta_w[cur:cur+Ll] = delta_full[Lg:]\n",
    "        segment_w[cur:cur+Ll] = 1\n",
    "\n",
    "    return {\n",
    "        \"seq_flux\": seq_flux_w,\n",
    "        \"pos_time\": pos_time_w,\n",
    "        \"pos_phase\": pos_phase_w,\n",
    "        \"delta\": delta_w,\n",
    "        \"segment_id\": segment_w,\n",
    "        \"attn_mask\": attn_mask,\n",
    "        \"special_mask\": special_m,\n",
    "        # payloads pour le modèle:\n",
    "        \"star_vec\": np.asarray(star_vec, dtype=np.float32),   # shape (S,)\n",
    "        \"phys_vec\": np.asarray(phys_vec, dtype=np.float32),   # shape (P,)\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Modèle: ajoute des embeddings dédiés pour [STAR] et [PHYS]\n",
    "# -----------------------------\n",
    "class MultiViewTransformerPhys(nn.Module):\n",
    "    def __init__(self,\n",
    "                 star_dim: int, phys_dim: int,\n",
    "                 d_model=256, nhead=8, num_layers=4, dim_feedforward=512, dropout=0.1,\n",
    "                 use_delta=True, segment_vocab_size=3,\n",
    "                 tabular_dim: int | None = None, tabular_hidden: int = 256, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.use_delta = use_delta\n",
    "\n",
    "        in_dim = 1 + 1 + 1 + (1 if use_delta else 0)  # flux + pos_time + pos_phase + delta\n",
    "        self.value_proj = nn.Linear(in_dim, d_model)\n",
    "        self.segment_embed = nn.Embedding(segment_vocab_size, d_model)\n",
    "\n",
    "        # Embeddings spéciaux\n",
    "        self.cls_embed  = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.trunc_normal_(self.cls_embed, std=0.02)\n",
    "        self.star_proj  = nn.Sequential(nn.Linear(star_dim, d_model), nn.ReLU(), nn.Dropout(dropout))\n",
    "        self.phys_proj  = nn.Sequential(nn.Linear(phys_dim, d_model), nn.ReLU(), nn.Dropout(dropout))\n",
    "\n",
    "        self.input_ln = nn.LayerNorm(d_model)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n",
    "                                               dim_feedforward=dim_feedforward,\n",
    "                                               dropout=dropout, batch_first=True, norm_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "\n",
    "        if tabular_dim is not None and tabular_dim > 0:\n",
    "            self.tabular_mlp = nn.Sequential(\n",
    "                nn.Linear(tabular_dim, tabular_hidden), nn.ReLU(), nn.Dropout(dropout),\n",
    "                nn.Linear(tabular_hidden, tabular_hidden), nn.ReLU()\n",
    "            )\n",
    "            self.cls_head = nn.Sequential(\n",
    "                nn.LayerNorm(d_model + tabular_hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(d_model + tabular_hidden, n_classes)\n",
    "            )\n",
    "        else:\n",
    "            self.tabular_mlp = None\n",
    "            self.cls_head = nn.Sequential(\n",
    "                nn.LayerNorm(d_model),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(d_model, n_classes)\n",
    "            )\n",
    "\n",
    "    def forward(self, batch, tabular=None):\n",
    "        # Projette les tokens data\n",
    "        parts = [batch[\"seq_flux\"].unsqueeze(-1),\n",
    "                 batch[\"pos_time\"].unsqueeze(-1),\n",
    "                 batch[\"pos_phase\"].unsqueeze(-1)]\n",
    "        if self.use_delta:\n",
    "            parts.append(batch[\"delta\"].unsqueeze(-1))\n",
    "        x = torch.cat(parts, dim=-1)  # (B, L, in_dim)\n",
    "        data_h = self.value_proj(x) + self.segment_embed(batch[\"segment_id\"])\n",
    "\n",
    "        # Construire les 3 premiers tokens: [CLS], [STAR], [PHYS]\n",
    "        B = x.size(0)\n",
    "        cls_tok  = self.cls_embed.expand(B, 1, self.d_model)               # (B,1,d)\n",
    "        star_tok = self.star_proj(batch[\"star_vec\"])[:, None, :]           # (B,1,d)\n",
    "        phys_tok = self.phys_proj(batch[\"phys_vec\"])[:, None, :]           # (B,1,d)\n",
    "\n",
    "        # Remplacer le début de data_h par nos trois embeddings spéciaux\n",
    "        h = data_h.clone()\n",
    "        h[:, 0:1, :] = cls_tok\n",
    "        h[:, 1:2, :] = star_tok\n",
    "        h[:, 2:3, :] = phys_tok\n",
    "        h = self.input_ln(h)\n",
    "\n",
    "        src_key_padding_mask = (batch[\"attn_mask\"] == 0)\n",
    "        z = self.encoder(h, src_key_padding_mask=src_key_padding_mask)\n",
    "        cls = z[:, 0, :]\n",
    "\n",
    "        if self.tabular_mlp is not None and tabular is not None:\n",
    "            t_emb = self.tabular_mlp(tabular)\n",
    "            cls = torch.cat([cls, t_emb], dim=-1)\n",
    "\n",
    "        logits = self.cls_head(cls)\n",
    "        return logits\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Batch builder avec [STAR] / [PHYS]\n",
    "# -----------------------------\n",
    "def make_batch_with_star_phys(views_list, star_list=None, phys_list=None, X_tsfresh_norm=None, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    views_list : liste de `views`\n",
    "    star_list  : liste de vecteurs STAR (S,)\n",
    "    phys_list  : liste de vecteurs PHYS (P,)\n",
    "    \"\"\"\n",
    "    seqs = []\n",
    "    if star_list is None or phys_list is None:\n",
    "        # auto-construction à partir des views (et éventuellement bls_out si stocké côté appelant)\n",
    "        star_list = []\n",
    "        phys_list = []\n",
    "        for v in views_list:\n",
    "            sv, pv = build_star_phys_features(v, star_info=None, bls_out=None)\n",
    "            star_list.append(sv); phys_list.append(pv)\n",
    "\n",
    "    for v, sv, pv in zip(views_list, star_list, phys_list):\n",
    "        seqs.append(build_concat_sequence_with_star_phys(v, sv, pv, add_sep_token=True))\n",
    "\n",
    "    def to_tensor(key, dtype=torch.float32):\n",
    "        arrs = [s[key] for s in seqs]\n",
    "        return torch.tensor(np.stack(arrs, axis=0), dtype=dtype, device=device)\n",
    "\n",
    "    batch = {\n",
    "        \"seq_flux\":  to_tensor(\"seq_flux\",  torch.float32),\n",
    "        \"pos_time\":  to_tensor(\"pos_time\",  torch.float32),\n",
    "        \"pos_phase\": to_tensor(\"pos_phase\", torch.float32),\n",
    "        \"delta\":     to_tensor(\"delta\",     torch.float32),\n",
    "        \"segment_id\":to_tensor(\"segment_id\",torch.long),\n",
    "        \"attn_mask\": to_tensor(\"attn_mask\", torch.long),\n",
    "        \"special_mask\": to_tensor(\"special_mask\", torch.long),\n",
    "        \"star_vec\":  to_tensor(\"star_vec\",  torch.float32),\n",
    "        \"phys_vec\":  to_tensor(\"phys_vec\",  torch.float32),\n",
    "    }\n",
    "\n",
    "    tab = None\n",
    "    if X_tsfresh_norm is not None:\n",
    "        tab = torch.tensor(np.asarray(X_tsfresh_norm), dtype=torch.float32, device=device)\n",
    "    return batch, tab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:30:11.482973Z",
     "iopub.status.busy": "2025-10-04T23:30:11.482699Z",
     "iopub.status.idle": "2025-10-04T23:30:11.658154Z",
     "shell.execute_reply": "2025-10-04T23:30:11.657405Z",
     "shell.execute_reply.started": "2025-10-04T23:30:11.482946Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Transformer+STAR+PHYS] logits shape: (1, 2)\n",
      "Logits: [[-1.5235722  0.9175039]]\n",
      "Probas (softmax): [[0.08009358 0.9199064 ]]\n",
      "Somme des probas: [0.99999994]\n",
      "OK: shape et valeurs finies.\n",
      "seq_flux: shape=(1, 2206)  (L=2206)\n",
      "pos_time: shape=(1, 2206)  (L=2206)\n",
      "pos_phase: shape=(1, 2206)  (L=2206)\n",
      "delta: shape=(1, 2206)  (L=2206)\n",
      "segment_id: shape=(1, 2206)  (L=2206)\n",
      "attn_mask: shape=(1, 2206)  (L=2206)\n",
      "special_mask: shape=(1, 2206)  (L=2206)\n",
      "STAR vec dim: (1, 6) | PHYS vec dim: (1, 5)\n",
      "special_mask sum: 4\n",
      "special first idx: [0, 1, 2, 2004]\n",
      "segment_id counts: {0: 2001, 1: 201, 2: 4}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5) Démo rapide (en gardant vos variables `views`, `tab` optionnel)\n",
    "# -----------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# (a) Construire automatiquement STAR/PHYS depuis views/meta (+bls_out si vous l’avez sous la main)\n",
    "sv, pv = build_star_phys_features(views, star_info=None, bls_out=globals().get(\"bls_out\", None))\n",
    "batch, tab = make_batch_with_star_phys([views], star_list=[sv], phys_list=[pv],\n",
    "                                       X_tsfresh_norm=None, device=device)\n",
    "\n",
    "# (b) Modèle avec dimensions STAR/PHYS déduites automatiquement\n",
    "star_dim = batch[\"star_vec\"].shape[-1]\n",
    "phys_dim = batch[\"phys_vec\"].shape[-1]\n",
    "\n",
    "model_phys = MultiViewTransformerPhys(\n",
    "    star_dim=star_dim, phys_dim=phys_dim,\n",
    "    d_model=256, nhead=8, num_layers=4, dim_feedforward=512, dropout=0.1,\n",
    "    use_delta=True, segment_vocab_size=3,\n",
    "    tabular_dim=(tab.shape[1] if tab is not None else None), tabular_hidden=256,\n",
    "    n_classes=2\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model_phys(batch, tabular=tab)\n",
    "print(\"[Transformer+STAR+PHYS] logits shape:\", tuple(logits.shape))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "with torch.no_grad():\n",
    "    probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Logits:\", logits.cpu().numpy())\n",
    "print(\"Probas (softmax):\", probs)\n",
    "print(\"Somme des probas:\", probs.sum(axis=1))\n",
    "\n",
    "# Vérifs rapides\n",
    "assert np.isfinite(logits.cpu().numpy()).all(), \"NaN/Inf détecté dans les logits.\"\n",
    "assert logits.shape == (1, 2), f\"Shape inattendu: {logits.shape}\"\n",
    "print(\"OK: shape et valeurs finies.\")\n",
    "\n",
    "# (optionnel) inspecter la longueur de séquence encodée\n",
    "for k in [\"seq_flux\",\"pos_time\",\"pos_phase\",\"delta\",\"segment_id\",\"attn_mask\",\"special_mask\"]:\n",
    "    print(f\"{k}: shape={tuple(batch[k].shape)}  (L={batch[k].shape[1]})\")\n",
    "print(\"STAR vec dim:\", tuple(batch[\"star_vec\"].shape), \"| PHYS vec dim:\", tuple(batch[\"phys_vec\"].shape))\n",
    "\n",
    "# Les 4 tokens spéciaux doivent être marqués (CLS, STAR, PHYS, SEP)\n",
    "print(\"special_mask sum:\", int(batch[\"special_mask\"].sum().item()))  # attendu: 4\n",
    "print(\"special first idx:\", torch.nonzero(batch[\"special_mask\"][0])[:5].squeeze().tolist())\n",
    "\n",
    "# Segments: 0=global, 1=local, 2=special\n",
    "vals, counts = torch.unique(batch[\"segment_id\"], return_counts=True)\n",
    "print(\"segment_id counts:\", dict(zip(vals.tolist(), counts.tolist())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture interne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:30:11.659352Z",
     "iopub.status.busy": "2025-10-04T23:30:11.659096Z",
     "iopub.status.idle": "2025-10-04T23:30:11.673363Z",
     "shell.execute_reply": "2025-10-04T23:30:11.672604Z",
     "shell.execute_reply.started": "2025-10-04T23:30:11.659334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# (C-2) Architecture interne — Transformer Encoder only\n",
    "# Options: profondeur, dim, têtes, dropout, et \"readout\" ([CLS] / [STAR] / [PHYS] / concat)\n",
    "# Compatible avec le batch créé précédemment (make_batch_with_star_phys)\n",
    "# ==========================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiViewTransformerPhysV2(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer Encoder pour classification binaire/multi-classe.\n",
    "    - Encodages d'entrée identiques (flux, pos_time, pos_phase, delta, segment_id)\n",
    "    - Tokens spéciaux: [CLS] (appris), [STAR] (proj. méta stellaires), [PHYS] (proj. priors transit)\n",
    "    - Readout configurable: 'cls' (par défaut), 'star', 'phys', 'concat' (concat des trois + MLP)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 star_dim: int, phys_dim: int,\n",
    "                 d_model: int = 192,            # 128–256 conseillé\n",
    "                 nhead: int = 4,                # 4 têtes (modéré)\n",
    "                 num_layers: int = 6,           # 4–6 blocs\n",
    "                 dim_feedforward: int = 384,    # 2x d_model ~ raisonnable\n",
    "                 dropout: float = 0.1,\n",
    "                 use_delta: bool = True,\n",
    "                 segment_vocab_size: int = 3,\n",
    "                 readout: str = \"cls\",          # 'cls' | 'star' | 'phys' | 'concat'\n",
    "                 tabular_dim: int | None = None,\n",
    "                 tabular_hidden: int = 256,\n",
    "                 n_classes: int = 2):\n",
    "        super().__init__()\n",
    "        assert readout in {\"cls\", \"star\", \"phys\", \"concat\"}\n",
    "        self.d_model = d_model\n",
    "        self.use_delta = use_delta\n",
    "        self.readout = readout\n",
    "\n",
    "        # Proj d'entrée (flux + pos encodings + delta optionnel)\n",
    "        in_dim = 1 + 1 + 1 + (1 if use_delta else 0)\n",
    "        self.value_proj = nn.Linear(in_dim, d_model)\n",
    "\n",
    "        # Embedding de segment (0=global,1=local,2=special)\n",
    "        self.segment_embed = nn.Embedding(segment_vocab_size, d_model)\n",
    "\n",
    "        # Embeddings spéciaux\n",
    "        self.cls_embed  = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.trunc_normal_(self.cls_embed, std=0.02)\n",
    "        self.star_proj  = nn.Sequential(nn.Linear(star_dim, d_model), nn.ReLU(), nn.Dropout(dropout))\n",
    "        self.phys_proj  = nn.Sequential(nn.Linear(phys_dim, d_model), nn.ReLU(), nn.Dropout(dropout))\n",
    "\n",
    "        # Norm + Transformer Encoder\n",
    "        self.input_ln = nn.LayerNorm(d_model)\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout, batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "\n",
    "        # Têtes de sortie selon le readout\n",
    "        out_dim = d_model\n",
    "        if readout == \"concat\":\n",
    "            out_dim = 3 * d_model  # concat [CLS],[STAR],[PHYS] encodés\n",
    "\n",
    "        # Fusion tabulaire (TSFRESH) optionnelle\n",
    "        if tabular_dim is not None and tabular_dim > 0:\n",
    "            self.tabular_mlp = nn.Sequential(\n",
    "                nn.Linear(tabular_dim, tabular_hidden), nn.ReLU(), nn.Dropout(dropout),\n",
    "                nn.Linear(tabular_hidden, tabular_hidden), nn.ReLU()\n",
    "            )\n",
    "            out_dim = out_dim + tabular_hidden\n",
    "        else:\n",
    "            self.tabular_mlp = None\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(out_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(out_dim, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, batch, tabular=None):\n",
    "        \"\"\"\n",
    "        batch: dict (B,L) avec clés:\n",
    "          seq_flux, pos_time, pos_phase, delta, segment_id, attn_mask,\n",
    "          star_vec (B,S), phys_vec (B,P)\n",
    "        \"\"\"\n",
    "        parts = [batch[\"seq_flux\"].unsqueeze(-1),\n",
    "                 batch[\"pos_time\"].unsqueeze(-1),\n",
    "                 batch[\"pos_phase\"].unsqueeze(-1)]\n",
    "        if self.use_delta:\n",
    "            parts.append(batch[\"delta\"].unsqueeze(-1))\n",
    "        x = torch.cat(parts, dim=-1)  # (B, L, in_dim)\n",
    "\n",
    "        data_h = self.value_proj(x) + self.segment_embed(batch[\"segment_id\"])\n",
    "\n",
    "        B = x.size(0)\n",
    "        cls_tok  = self.cls_embed.expand(B, 1, self.d_model)\n",
    "        star_tok = self.star_proj(batch[\"star_vec\"])[:, None, :]\n",
    "        phys_tok = self.phys_proj(batch[\"phys_vec\"])[:, None, :]\n",
    "\n",
    "        # Remplacer les 3 premiers tokens par nos spéciaux\n",
    "        h = data_h.clone()\n",
    "        h[:, 0:1, :] = cls_tok   # [CLS]\n",
    "        h[:, 1:2, :] = star_tok  # [STAR]\n",
    "        h[:, 2:3, :] = phys_tok  # [PHYS]\n",
    "        h = self.input_ln(h)\n",
    "\n",
    "        src_key_padding_mask = (batch[\"attn_mask\"] == 0)\n",
    "        z = self.encoder(h, src_key_padding_mask=src_key_padding_mask)  # (B,L,d)\n",
    "\n",
    "        # Readout\n",
    "        if self.readout == \"cls\":\n",
    "            rep = z[:, 0, :]\n",
    "        elif self.readout == \"star\":\n",
    "            rep = z[:, 1, :]\n",
    "        elif self.readout == \"phys\":\n",
    "            rep = z[:, 2, :]\n",
    "        else:  # 'concat'\n",
    "            rep = torch.cat([z[:, 0, :], z[:, 1, :], z[:, 2, :]], dim=-1)\n",
    "\n",
    "        # Fusion tabulaire (late fusion)\n",
    "        if self.tabular_mlp is not None and tabular is not None:\n",
    "            t_emb = self.tabular_mlp(tabular)\n",
    "            rep = torch.cat([rep, t_emb], dim=-1)\n",
    "\n",
    "        logits = self.head(rep)\n",
    "        return logits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:30:11.674419Z",
     "iopub.status.busy": "2025-10-04T23:30:11.674152Z",
     "iopub.status.idle": "2025-10-04T23:30:11.721836Z",
     "shell.execute_reply": "2025-10-04T23:30:11.721157Z",
     "shell.execute_reply.started": "2025-10-04T23:30:11.674396Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V2] logits shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# ===== Exemple d'instanciation (garde les mêmes variables que précédemment) =====\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "star_dim = batch[\"star_vec\"].shape[-1]\n",
    "phys_dim = batch[\"phys_vec\"].shape[-1]\n",
    "\n",
    "model_v2 = MultiViewTransformerPhysV2(\n",
    "    star_dim=star_dim, phys_dim=phys_dim,\n",
    "    d_model=192, nhead=4, num_layers=6, dim_feedforward=384, dropout=0.1,\n",
    "    use_delta=True, segment_vocab_size=3,\n",
    "    readout=\"cls\",                                # 'cls'|'star'|'phys'|'concat'\n",
    "    tabular_dim=(tab.shape[1] if tab is not None else None),\n",
    "    tabular_hidden=256,\n",
    "    n_classes=2\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_v2 = model_v2(batch, tabular=tab)\n",
    "\n",
    "print(\"[V2] logits shape:\", tuple(logits_v2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Têtes de sortie (multi-tâches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:30:11.722940Z",
     "iopub.status.busy": "2025-10-04T23:30:11.722679Z",
     "iopub.status.idle": "2025-10-04T23:30:11.799224Z",
     "shell.execute_reply": "2025-10-04T23:30:11.798593Z",
     "shell.execute_reply.started": "2025-10-04T23:30:11.722914Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MT] keys: ['logit', 'p_planet', 'P_days', 'depth', 'duration_days']\n",
      "[MT] shapes: {'logit': (1,), 'p_planet': (1,), 'P_days': (1,), 'depth': (1,), 'duration_days': (1,)}\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Têtes de sortie multi-tâches (classification + régressions physiques)\n",
    "# Compatible avec: batch, tab, star_dim, phys_dim\n",
    "# S'appuie sur l'architecture interne précédente (Encoder-only)\n",
    "# ==========================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiViewTransformerPhysV2MT(nn.Module):\n",
    "    \"\"\"\n",
    "    Variante multi-tâches de V2:\n",
    "      - Classification binaire (logits -> prob = sigmoid)\n",
    "      - Régressions: P (jours), depth (ΔF), duration (jours)\n",
    "    Readout identique: 'cls' | 'star' | 'phys' | 'concat'\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 star_dim: int, phys_dim: int,\n",
    "                 d_model: int = 192, nhead: int = 4, num_layers: int = 6,\n",
    "                 dim_feedforward: int = 384, dropout: float = 0.1,\n",
    "                 use_delta: bool = True, segment_vocab_size: int = 3,\n",
    "                 readout: str = \"cls\",\n",
    "                 tabular_dim: int | None = None, tabular_hidden: int = 256,\n",
    "                 n_classes: int = 2):\n",
    "        super().__init__()\n",
    "        assert readout in {\"cls\", \"star\", \"phys\", \"concat\"}\n",
    "        self.d_model = d_model\n",
    "        self.use_delta = use_delta\n",
    "        self.readout = readout\n",
    "\n",
    "        in_dim = 1 + 1 + 1 + (1 if use_delta else 0)\n",
    "        self.value_proj = nn.Linear(in_dim, d_model)\n",
    "        self.segment_embed = nn.Embedding(segment_vocab_size, d_model)\n",
    "\n",
    "        # Specials\n",
    "        self.cls_embed  = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.trunc_normal_(self.cls_embed, std=0.02)\n",
    "        self.star_proj  = nn.Sequential(nn.Linear(star_dim, d_model), nn.ReLU(), nn.Dropout(dropout))\n",
    "        self.phys_proj  = nn.Sequential(nn.Linear(phys_dim, d_model), nn.ReLU(), nn.Dropout(dropout))\n",
    "\n",
    "        self.input_ln = nn.LayerNorm(d_model)\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout,\n",
    "            batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "\n",
    "        # Readout dimension\n",
    "        rep_dim = d_model if readout != \"concat\" else (3 * d_model)\n",
    "\n",
    "        # Late fusion tabulaire (TSFRESH)\n",
    "        self.tabular_mlp = None\n",
    "        if tabular_dim is not None and tabular_dim > 0:\n",
    "            self.tabular_mlp = nn.Sequential(\n",
    "                nn.Linear(tabular_dim, tabular_hidden), nn.ReLU(), nn.Dropout(dropout),\n",
    "                nn.Linear(tabular_hidden, tabular_hidden), nn.ReLU()\n",
    "            )\n",
    "            rep_dim += tabular_hidden\n",
    "\n",
    "        # Heads\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.LayerNorm(rep_dim), nn.Dropout(dropout), nn.Linear(rep_dim, 1)  # binaire\n",
    "        )\n",
    "        self.regP_head = nn.Sequential(\n",
    "            nn.LayerNorm(rep_dim), nn.Dropout(dropout), nn.Linear(rep_dim, 1)  # période (jours)\n",
    "        )\n",
    "        self.regD_head = nn.Sequential(\n",
    "            nn.LayerNorm(rep_dim), nn.Dropout(dropout), nn.Linear(rep_dim, 1)  # depth (ΔF)\n",
    "        )\n",
    "        self.regT_head = nn.Sequential(\n",
    "            nn.LayerNorm(rep_dim), nn.Dropout(dropout), nn.Linear(rep_dim, 1)  # durée (jours)\n",
    "        )\n",
    "\n",
    "    def forward(self, batch, tabular=None, return_rep=False):\n",
    "        # Inputs -> encoder\n",
    "        parts = [batch[\"seq_flux\"].unsqueeze(-1),\n",
    "                 batch[\"pos_time\"].unsqueeze(-1),\n",
    "                 batch[\"pos_phase\"].unsqueeze(-1)]\n",
    "        if self.use_delta:\n",
    "            parts.append(batch[\"delta\"].unsqueeze(-1))\n",
    "        x = torch.cat(parts, dim=-1)\n",
    "\n",
    "        data_h = self.value_proj(x) + self.segment_embed(batch[\"segment_id\"])\n",
    "\n",
    "        B = x.size(0)\n",
    "        cls_tok  = self.cls_embed.expand(B, 1, self.d_model)\n",
    "        star_tok = self.star_proj(batch[\"star_vec\"])[:, None, :]\n",
    "        phys_tok = self.phys_proj(batch[\"phys_vec\"])[:, None, :]\n",
    "\n",
    "        h = data_h.clone()\n",
    "        h[:, 0:1, :] = cls_tok\n",
    "        h[:, 1:2, :] = star_tok\n",
    "        h[:, 2:3, :] = phys_tok\n",
    "        h = self.input_ln(h)\n",
    "\n",
    "        z = self.encoder(h, src_key_padding_mask=(batch[\"attn_mask\"] == 0))\n",
    "\n",
    "        # Readout vector\n",
    "        if self.readout == \"cls\":\n",
    "            rep = z[:, 0, :]\n",
    "        elif self.readout == \"star\":\n",
    "            rep = z[:, 1, :]\n",
    "        elif self.readout == \"phys\":\n",
    "            rep = z[:, 2, :]\n",
    "        else:\n",
    "            rep = torch.cat([z[:, 0, :], z[:, 1, :], z[:, 2, :]], dim=-1)\n",
    "\n",
    "        if self.tabular_mlp is not None and tabular is not None:\n",
    "            t_emb = self.tabular_mlp(tabular)\n",
    "            rep = torch.cat([rep, t_emb], dim=-1)\n",
    "\n",
    "        # Heads\n",
    "        logit = self.cls_head(rep).squeeze(-1)             # (B,)\n",
    "        p_planet = torch.sigmoid(logit)                    # proba\n",
    "        pred_P = self.regP_head(rep).squeeze(-1)           # (B,)\n",
    "        pred_depth = self.regD_head(rep).squeeze(-1)       # (B,)\n",
    "        pred_dur = self.regT_head(rep).squeeze(-1)         # (B,)\n",
    "\n",
    "        out = {\n",
    "            \"logit\": logit, \"p_planet\": p_planet,\n",
    "            \"P_days\": pred_P, \"depth\": pred_depth, \"duration_days\": pred_dur\n",
    "        }\n",
    "        if return_rep:\n",
    "            out[\"rep\"] = rep\n",
    "        return out\n",
    "\n",
    "# ===== Instanciation (mêmes variables) =====\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_mt = MultiViewTransformerPhysV2MT(\n",
    "    star_dim=star_dim, phys_dim=phys_dim,\n",
    "    d_model=192, nhead=4, num_layers=6, dim_feedforward=384, dropout=0.1,\n",
    "    use_delta=True, segment_vocab_size=3,\n",
    "    readout=\"cls\",\n",
    "    tabular_dim=(tab.shape[1] if tab is not None else None), tabular_hidden=256,\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model_mt(batch, tabular=tab)\n",
    "print(\"[MT] keys:\", list(out.keys()))\n",
    "print(\"[MT] shapes:\", {k: tuple(v.shape) for k,v in out.items() if hasattr(v, 'shape')})\n",
    "\n",
    "# ==========================================================\n",
    "# Perte multi-tâches (exemple) — pondérations ajustables\n",
    "#   - Classification: BCEWithLogitsLoss (logit brut)\n",
    "#   - Régressions: MSE (ou L1), avec masques pour cibles manquantes\n",
    "# ==========================================================\n",
    "def multitask_loss(out, y_bin,\n",
    "                   y_P=None, y_depth=None, y_dur=None,\n",
    "                   w_cls=1.0, w_P=0.2, w_depth=0.2, w_dur=0.2):\n",
    "    \"\"\"\n",
    "    y_bin: tensor (B,) binaire {0,1}\n",
    "    y_*  : tensors (B,) avec NaN si inconnu (masqué automatiquement)\n",
    "    \"\"\"\n",
    "    # Classification\n",
    "    bce = F.binary_cross_entropy_with_logits(out[\"logit\"], y_bin.float())\n",
    "\n",
    "    # Helper régression avec masque\n",
    "    def masked_mse(pred, target):\n",
    "        if target is None: return torch.tensor(0.0, device=pred.device)\n",
    "        m = torch.isfinite(target)\n",
    "        if m.any():\n",
    "            return F.mse_loss(pred[m], target[m])\n",
    "        return torch.tensor(0.0, device=pred.device)\n",
    "\n",
    "    lossP = masked_mse(out[\"P_days\"], y_P)\n",
    "    lossD = masked_mse(out[\"depth\"], y_depth)\n",
    "    lossT = masked_mse(out[\"duration_days\"], y_dur)\n",
    "\n",
    "    total = w_cls*bce + w_P*lossP + w_depth*lossD + w_dur*lossT\n",
    "    return total, {\"bce\": bce.item(), \"lossP\": lossP.item(), \"lossD\": lossD.item(), \"lossT\": lossT.item()}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:30:11.800158Z",
     "iopub.status.busy": "2025-10-04T23:30:11.799955Z",
     "iopub.status.idle": "2025-10-04T23:30:12.041906Z",
     "shell.execute_reply": "2025-10-04T23:30:12.041243Z",
     "shell.execute_reply.started": "2025-10-04T23:30:11.800141Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MT] loss total: 0.7311 | détails: {'bce': 0.7311391234397888, 'lossP': 0.0, 'lossD': 0.0, 'lossT': 0.0}\n",
      "[MC-Dropout] p(mean)= [0.52195925]  | p(std)= [0.0539929]\n"
     ]
    }
   ],
   "source": [
    "# ===== Mini démo (labels factices pour vérifier le câblage) =====\n",
    "B = batch[\"seq_flux\"].shape[0]\n",
    "y_bin = torch.zeros(B, device=device)           # ex: tous \"non-planète\" pour le test\n",
    "y_P   = torch.full((B,), float('nan'), device=device)  # pas de labels physiques -> masqués\n",
    "y_D   = torch.full((B,), float('nan'), device=device)\n",
    "y_T   = torch.full((B,), float('nan'), device=device)\n",
    "\n",
    "loss, parts = multitask_loss(out, y_bin, y_P, y_D, y_T, w_cls=1.0, w_P=0.1, w_depth=0.1, w_dur=0.1)\n",
    "print(f\"[MT] loss total: {loss.item():.4f} | détails:\", parts)\n",
    "\n",
    "# ==========================================================\n",
    "# (Optionnel) Inférence avec Dropout Monte Carlo pour approx. incertitude\n",
    "# ==========================================================\n",
    "def predict_mc_dropout(model, batch, tabular=None, n_samples: int = 20):\n",
    "    model.train()  # active dropout\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            o = model(batch, tabular=tabular)\n",
    "            probs.append(o[\"p_planet\"].detach().cpu())\n",
    "    probs = torch.stack(probs, dim=0).numpy()   # (S,B)\n",
    "    return probs.mean(axis=0), probs.std(axis=0)  # (B,), (B,)\n",
    "\n",
    "mean_p, std_p = predict_mc_dropout(model_mt, batch, tabular=tab, n_samples=10)\n",
    "print(\"[MC-Dropout] p(mean)=\", mean_p, \" | p(std)=\", std_p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:30:12.042983Z",
     "iopub.status.busy": "2025-10-04T23:30:12.042711Z",
     "iopub.status.idle": "2025-10-04T23:30:12.086082Z",
     "shell.execute_reply": "2025-10-04T23:30:12.085307Z",
     "shell.execute_reply.started": "2025-10-04T23:30:12.042960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# (D) Entraînement — déséquilibre fort (Focal Loss), early stopping sur PR-AUC,\n",
    "#     + pré-entraînement auto-supervisé léger (masked reconstruction) optionnel\n",
    "# Hypothèses (même logique / mêmes variables) :\n",
    "#   - Vous avez df, cfg, infer_time_flux_columns, group_iter,\n",
    "#     preprocess_single_lightcurve, build_multires_views,\n",
    "#     build_star_phys_features, make_batch_with_star_phys\n",
    "#   - Le modèle multi-tâches existe : `model_mt = MultiViewTransformerPhysV2MT(...)`\n",
    "#   - Un mapping labels existe : `labels_by_gid: dict[str, int]` (0/1)\n",
    "#     (si vous n’en avez pas encore, je montre un stub de démonstration)\n",
    "# ==========================================================\n",
    "import numpy as np, pandas as pd, time, math, random, warnings\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Dataset -> construit (views, STAR/PHYS) par groupe\n",
    "# =========================\n",
    "# PATCH CACHE MultiViewDataset\n",
    "# =========================\n",
    "class MultiViewDataset(Dataset):\n",
    "    def __init__(self, df, cfg,\n",
    "                 time_col: str, flux_col: str,\n",
    "                 labels_by_gid: dict,\n",
    "                 run_bls: bool = False,\n",
    "                 bls_params: dict | None = None,\n",
    "                 max_groups: int | None = None,\n",
    "                 seed: int = 42):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.time_col = time_col\n",
    "        self.flux_col = flux_col\n",
    "        self.labels_by_gid = labels_by_gid\n",
    "        self.run_bls = run_bls\n",
    "        self.bls_params = bls_params or {}\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "\n",
    "        groups = list(group_iter(self.df))\n",
    "        if max_groups is not None:\n",
    "            groups = groups[:max_groups]\n",
    "        self.groups = []\n",
    "        for gid, sub in groups:\n",
    "            if gid in labels_by_gid:\n",
    "                self.groups.append((gid, sub.sort_values(self.time_col)))\n",
    "\n",
    "        # ---- AJOUT: cache par gid ----\n",
    "        # gid -> sample dict {\"batch\":..., \"y\":..., \"gid\":..., \"meta\":...}\n",
    "        self._cache: dict[str, dict] = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gid, sub = self.groups[idx]\n",
    "\n",
    "        # ---- SERVIR DEPUIS LE CACHE SI DISPONIBLE ----\n",
    "        if gid in self._cache:\n",
    "            return self._cache[gid]\n",
    "\n",
    "        # ---------- Prétraitement ----------\n",
    "        proc = preprocess_single_lightcurve(sub, self.time_col, self.flux_col, self.cfg)\n",
    "\n",
    "        # ---------- BLS optionnel ----------\n",
    "        bls_out = None\n",
    "        if self.run_bls:\n",
    "            try:\n",
    "                # bornes sécurisées par pmin\n",
    "                t_uni = np.asarray(proc[\"time_uniform\"])\n",
    "                pmin, pmax, _ = estimate_period_bounds(\n",
    "                    t_uni,\n",
    "                    min_hours=self.bls_params.get(\"min_period_hours\", 7.0),\n",
    "                    max_frac_baseline=self.bls_params.get(\"max_period_frac_baseline\", 0.9)\n",
    "                )\n",
    "                dmin_h, dmax_h_req = self.bls_params.get(\"durations_hours\", (1.0, 12.0))\n",
    "                dmax_h_safe = min(dmax_h_req, 0.8 * pmin * 24.0)\n",
    "                if not np.isfinite(dmax_h_safe) or dmax_h_safe <= dmin_h:\n",
    "                    dmax_h_safe = max(dmin_h + 0.25, dmin_h * 1.5)\n",
    "\n",
    "                bls_out = run_bls_on_proc(\n",
    "                    proc,\n",
    "                    n_periods=self.bls_params.get(\"n_periods\", 5000),\n",
    "                    min_period_hours=24.0 * pmin,\n",
    "                    max_period_frac_baseline=self.bls_params.get(\"max_period_frac_baseline\", 0.9),\n",
    "                    durations_hours=(dmin_h, dmax_h_safe),\n",
    "                    n_durations=self.bls_params.get(\"n_durations\", 10),\n",
    "                    top_k=self.bls_params.get(\"top_k\", 1)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[BLS] Skip {gid}: {e}\")\n",
    "                bls_out = None\n",
    "\n",
    "        # ---------- Vues multi-résolution ----------\n",
    "        views = build_multires_views(proc, bls_out=bls_out,\n",
    "                                     N_GLOBAL=2001, N_LOCAL=201, window_factor=2.0)\n",
    "\n",
    "        # ---------- STAR/PHYS ----------\n",
    "        star_vec, phys_vec = build_star_phys_features(views, star_info=None, bls_out=bls_out)\n",
    "\n",
    "        # ---------- Batch ----------\n",
    "        batch, _ = make_batch_with_star_phys([views], [star_vec], [phys_vec], device=\"cpu\")\n",
    "        y = int(self.labels_by_gid.get(gid, 0))\n",
    "        sample = {\"batch\": batch, \"y\": y, \"gid\": gid, \"meta\": views[\"meta\"]}\n",
    "\n",
    "        # ---- STOCKER EN CACHE ----\n",
    "        self._cache[gid] = sample\n",
    "        return sample\n",
    "\n",
    "    # (Optionnel) utilitaire pour vider/préremplir le cache\n",
    "    def clear_cache(self):\n",
    "        self._cache.clear()\n",
    "\n",
    "    def warm_cache(self, max_items: int | None = None, show_progress: bool = True):\n",
    "        \"\"\"\n",
    "        Pré-calcule et met en cache les sorties pour chaque gid (BLS + vues).\n",
    "        max_items: limite optionnelle pour ne pas tout précalculer.\n",
    "        \"\"\"\n",
    "        n = len(self)\n",
    "        n_iter = n if max_items is None else min(n, max_items)\n",
    "        it = range(n_iter)\n",
    "        if show_progress:\n",
    "            print(f\"[Cache] warm-up {n_iter}/{n} items ...\")\n",
    "        for i in it:\n",
    "            _ = self[i]   # __getitem__ remplit self._cache[gid]\n",
    "        if show_progress:\n",
    "            print(\"[Cache] warm-up done.\")\n",
    "        return None\n",
    "\n",
    "def collate_mv(samples, to_device=None):\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    if to_device is None:\n",
    "        to_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Clés séquentielles à pader\n",
    "    seq_keys = [\"seq_flux\",\"pos_time\",\"pos_phase\",\"delta\",\"segment_id\",\n",
    "                \"attn_mask\",\"special_mask\"]\n",
    "    other_keys = [\"star_vec\",\"phys_vec\"]\n",
    "\n",
    "    # Longueurs L par sample\n",
    "    Ls = [int(s[\"batch\"][\"seq_flux\"].shape[1]) for s in samples]\n",
    "    Lmax = max(Ls)\n",
    "\n",
    "    def pad1(t, Lmax, pad_value=0):\n",
    "        # t: (L,) -> (Lmax,)\n",
    "        L = t.shape[0]\n",
    "        if L == Lmax:\n",
    "            return t\n",
    "        pad = torch.full((Lmax - L,), pad_value, dtype=t.dtype, device=t.device)\n",
    "        return torch.cat([t, pad], dim=0)\n",
    "\n",
    "    # Empilement avec padding\n",
    "    batch = {}\n",
    "    for k in seq_keys:\n",
    "        tt = []\n",
    "        for s in samples:\n",
    "            v = s[\"batch\"][k][0]  # (L,)\n",
    "            if k in [\"segment_id\",\"attn_mask\",\"special_mask\"]:\n",
    "                # segment_id: on met 2 (=special) pour le padding ; masks: 0 pour padding\n",
    "                pad_val = 2 if k==\"segment_id\" else 0\n",
    "            else:\n",
    "                pad_val = 0\n",
    "            tt.append(pad1(v, Lmax, pad_value=pad_val))\n",
    "        batch[k] = torch.stack(tt, dim=0).to(to_device)\n",
    "\n",
    "    for k in other_keys:\n",
    "        batch[k] = torch.stack([s[\"batch\"][k][0] for s in samples], dim=0).to(to_device)\n",
    "\n",
    "    y = torch.tensor([s[\"y\"] for s in samples], dtype=torch.long, device=to_device)\n",
    "    gids = [s[\"gid\"] for s in samples]\n",
    "    return batch, y, gids\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Focal Loss pour déséquilibre\n",
    "# -----------------------------\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: float = 0.25, gamma: float = 2.0, reduction: str = \"mean\"):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor):\n",
    "        \"\"\"\n",
    "        logits: (B,) — bruts (pas de sigmoid)\n",
    "        targets: (B,) — 0/1\n",
    "        \"\"\"\n",
    "        p = torch.sigmoid(logits)\n",
    "        ce = F.binary_cross_entropy_with_logits(logits, targets.float(), reduction=\"none\")\n",
    "        pt = p * targets + (1 - p) * (1 - targets)  # p_t\n",
    "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "        loss = alpha_t * ((1 - pt) ** self.gamma) * ce\n",
    "        if self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Boucle d'entraînement / évaluation\n",
    "# -----------------------------\n",
    "def evaluate_pr_auc(model, loader):\n",
    "    model.eval()\n",
    "    all_p, all_y = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch, y, _ in loader:\n",
    "            out = model(batch, tabular=None)\n",
    "            p = out[\"p_planet\"].detach().cpu().numpy()\n",
    "            all_p.append(p)\n",
    "            all_y.append(y.detach().cpu().numpy())\n",
    "    all_p = np.concatenate(all_p); all_y = np.concatenate(all_y)\n",
    "    try:\n",
    "        ap = average_precision_score(all_y, all_p)\n",
    "    except Exception:\n",
    "        ap = float(\"nan\")\n",
    "    # petit diagnostic : rappel à haute précision (ex: précision >= 0.95)\n",
    "    prec, rec, thr = precision_recall_curve(all_y, all_p)\n",
    "    high_prec_recall = float(rec[prec >= 0.95].max()) if (prec >= 0.95).any() else 0.0\n",
    "    return ap, high_prec_recall, (prec, rec, thr)\n",
    "\n",
    "def train_supervised(model, train_loader, val_loader,\n",
    "                     n_epochs: int = 10,\n",
    "                     lr: float = 3e-4,\n",
    "                     use_focal: bool = True,\n",
    "                     class_weight_neg: float = 1.0, class_weight_pos: float = 3.0,\n",
    "                     early_stop_patience: int = 3,\n",
    "                     print_every: int = 1):\n",
    "    model.train()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    # focal loss ou BCE pondérée\n",
    "    if use_focal:\n",
    "        criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "    else:\n",
    "        pos_weight = torch.tensor(class_weight_pos / class_weight_neg, device=device)\n",
    "        criterion = lambda logit, y: F.binary_cross_entropy_with_logits(logit, y.float(), pos_weight=pos_weight)\n",
    "\n",
    "    best_val_ap = -np.inf\n",
    "    patience = 0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model.train()\n",
    "        running = 0.0; n_batches = 0\n",
    "        for batch, y, _ in train_loader:\n",
    "            opt.zero_grad()\n",
    "            out = model(batch, tabular=None)\n",
    "            loss = criterion(out[\"logit\"], y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            running += float(loss.item()); n_batches += 1\n",
    "\n",
    "        # Eval\n",
    "        val_ap, val_rec95, _ = evaluate_pr_auc(model, val_loader)\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print(f\"[Epoch {epoch:02d}] loss={running/max(1,n_batches):.4f} | val AP={val_ap:.4f} | R@P>=0.95={val_rec95:.3f}\")\n",
    "\n",
    "        # Early stopping sur PR-AUC\n",
    "        if val_ap > best_val_ap + 1e-4:\n",
    "            best_val_ap = val_ap\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= early_stop_patience:\n",
    "                print(f\"[EarlyStop] Pas d’amélioration AP pendant {early_stop_patience} epochs. Stop.\")\n",
    "                break\n",
    "\n",
    "    # restore meilleur\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return best_val_ap\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Pré-entraînement auto-supervisé (masked reconstruction) — rapide\n",
    "#     On masque au hasard une fraction des points séquence (hors tokens spéciaux)\n",
    "#     et on apprend à prédire `seq_flux` original (MSE). 2–4 epochs suffisent.\n",
    "# -----------------------------\n",
    "class MTReconstructionHead(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, 1))\n",
    "    def forward(self, z):  # (B,L,d) -> (B,L)\n",
    "        return self.head(z).squeeze(-1)\n",
    "\n",
    "def _crop_batch_keep_specials(batch, crop_len=512):\n",
    "    \"\"\"\n",
    "    Garde les 3 premiers tokens spéciaux puis prend un crop contigu de longueur crop_len\n",
    "    dans le reste de la séquence. Retourne un nouveau batch 'croppé' (copie).\n",
    "    \"\"\"\n",
    "    B, L = batch[\"seq_flux\"].shape\n",
    "    # positions possibles pour le début (après les 3 spéciaux)\n",
    "    start_min = 3\n",
    "    start_max = max(start_min, L - crop_len)\n",
    "    if start_min >= L:\n",
    "        return batch  # rien à faire si séquence courte\n",
    "\n",
    "    starts = torch.randint(low=start_min, high=start_max+1, size=(B,), device=batch[\"seq_flux\"].device)\n",
    "    idxs = []\n",
    "    for b in range(B):\n",
    "        s = int(starts[b].item())\n",
    "        e = min(L, s + crop_len)\n",
    "        take = torch.cat([torch.arange(0, 3, device=batch[\"seq_flux\"].device),  # specials\n",
    "                          torch.arange(s, e, device=batch[\"seq_flux\"].device)])\n",
    "        idxs.append(take)\n",
    "    idxs = torch.stack(idxs, dim=0)  # (B, 3+crop)\n",
    "\n",
    "    cropped = {}\n",
    "    for k, t in batch.items():\n",
    "        if t.dim() == 2 and t.size(1) == L:\n",
    "            # (B,L) -> gather par batch\n",
    "            ar = []\n",
    "            for b in range(B):\n",
    "                ar.append(t[b].index_select(0, idxs[b]))\n",
    "            cropped[k] = torch.stack(ar, dim=0)\n",
    "        else:\n",
    "            cropped[k] = t  # star_vec/phys_vec (B,S/P) inchangés\n",
    "    return cropped\n",
    "\n",
    "def pretrain_masked_reconstruction_fast(model_mt, train_loader,\n",
    "                                        mask_frac: float = 0.15,\n",
    "                                        n_epochs: int = 2,\n",
    "                                        lr: float = 3e-4,\n",
    "                                        crop_len: int = 512,\n",
    "                                        max_batches_per_epoch: int = 50,\n",
    "                                        amp: bool = True):\n",
    "    \"\"\"\n",
    "    Pré-entrainement auto-supervisé allégé :\n",
    "      - crop de la séquence après les 3 tokens spéciaux pour réduire L\n",
    "      - reconstruction MSE sur positions masquées\n",
    "      - AMP pour accélérer\n",
    "      - limite de batches/epoch pour éviter de traîner\n",
    "    \"\"\"\n",
    "    device = next(model_mt.parameters()).device\n",
    "    recon_head = MTReconstructionHead(model_mt.d_model).to(device)\n",
    "    params = list(model_mt.parameters()) + list(recon_head.parameters())\n",
    "    opt = torch.optim.AdamW(params, lr=lr)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "\n",
    "    def forward_tokens(model, batch):\n",
    "        parts = [batch[\"seq_flux\"].unsqueeze(-1),\n",
    "                 batch[\"pos_time\"].unsqueeze(-1),\n",
    "                 batch[\"pos_phase\"].unsqueeze(-1)]\n",
    "        if model.use_delta:\n",
    "            parts.append(batch[\"delta\"].unsqueeze(-1))\n",
    "        x = torch.cat(parts, dim=-1)\n",
    "        data_h = model.value_proj(x) + model.segment_embed(batch[\"segment_id\"])\n",
    "        B = x.size(0)\n",
    "        cls_tok  = model.cls_embed.expand(B, 1, model.d_model)\n",
    "        star_tok = model.star_proj(batch[\"star_vec\"])[:, None, :]\n",
    "        phys_tok = model.phys_proj(batch[\"phys_vec\"])[:, None, :]\n",
    "        h = data_h.clone()\n",
    "        h[:, 0:1, :] = cls_tok\n",
    "        h[:, 1:2, :] = star_tok\n",
    "        h[:, 2:3, :] = phys_tok\n",
    "        h = model.input_ln(h)\n",
    "        z = model.encoder(h, src_key_padding_mask=(batch[\"attn_mask\"] == 0))\n",
    "        return z\n",
    "\n",
    "    model_mt.train(); recon_head.train()\n",
    "    for ep in range(1, n_epochs+1):\n",
    "        running, nb = 0.0, 0\n",
    "        for b_i, (batch, _, _) in enumerate(train_loader, start=1):\n",
    "            if b_i > max_batches_per_epoch:\n",
    "                break\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            # === Crop rapide ===\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            batch_c = _crop_batch_keep_specials(batch, crop_len=crop_len)\n",
    "\n",
    "            # === Masquage ===\n",
    "            Lc = batch_c[\"seq_flux\"].shape[1]\n",
    "            special = (batch_c[\"special_mask\"] == 1)\n",
    "            can_mask = (~special)\n",
    "            mask = torch.zeros_like(batch_c[\"seq_flux\"], dtype=torch.bool)\n",
    "            # échantillonne ~mask_frac par échantillon\n",
    "            for b in range(batch_c[\"seq_flux\"].shape[0]):\n",
    "                idx = torch.nonzero(can_mask[b]).squeeze(-1)\n",
    "                k = max(1, int(len(idx) * mask_frac))\n",
    "                choice = idx[torch.randperm(len(idx), device=idx.device)[:k]]\n",
    "                mask[b, choice] = True\n",
    "\n",
    "            target = batch_c[\"seq_flux\"].detach().clone()\n",
    "            noisy = batch_c[\"seq_flux\"].clone()\n",
    "            noisy = noisy + 0.01 * torch.randn_like(noisy)\n",
    "            noisy[mask] = 0.0\n",
    "            seq_flux_orig = batch_c[\"seq_flux\"]\n",
    "            batch_c[\"seq_flux\"] = noisy\n",
    "\n",
    "            # === Forward + loss (AMP) ===\n",
    "            with torch.cuda.amp.autocast(enabled=amp):\n",
    "                z = forward_tokens(model_mt, batch_c)     # (B,Lc,d)\n",
    "                pred = recon_head(z)                      # (B,Lc)\n",
    "                loss = F.mse_loss(pred[mask], target[mask])\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            nn.utils.clip_grad_norm_(params, 1.0)\n",
    "            scaler.step(opt); scaler.update()\n",
    "\n",
    "            # restore\n",
    "            batch_c[\"seq_flux\"] = seq_flux_orig\n",
    "\n",
    "            running += float(loss.item()); nb += 1\n",
    "\n",
    "        print(f\"[SSL FAST] epoch {ep}/{n_epochs} | loss={running/max(1,nb):.6f} | batches={nb} | crop_len={crop_len}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T23:30:12.087078Z",
     "iopub.status.busy": "2025-10-04T23:30:12.086840Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cache] warm-up validation …\n",
      "[Cache] warm-up 10/10 items ...\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=13.005259 j | dur=5.60 h | window ±2.0×dur -> ±0.0359 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=0.884147 j | dur=1.50 h | window ±2.0×dur -> ±0.1414 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=4.413771 j | dur=3.80 h | window ±2.0×dur -> ±0.0717 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=3.290581 j | dur=3.20 h | window ±2.0×dur -> ±0.0810 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=16.212571 j | dur=5.60 h | window ±2.0×dur -> ±0.0288 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=21.753579 j | dur=4.60 h | window ±2.0×dur -> ±0.0176 phase]\n",
      "[Note] Cas 'single-transit-like' détecté: P possiblement mal contrainte.\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=5.662544 j | dur=3.20 h | window ±2.0×dur -> ±0.0471 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=6.070960 j | dur=2.20 h | window ±2.0×dur -> ±0.0302 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=13.061843 j | dur=5.60 h | window ±2.0×dur -> ±0.0357 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=13.952169 j | dur=5.60 h | window ±2.0×dur -> ±0.0334 phase]\n",
      "[Cache] warm-up done.\n",
      "[Cache] warm-up done.\n",
      "[Data] train groups=40 | val groups=10\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=4.420270 j | dur=3.20 h | window ±2.0×dur -> ±0.0603 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=11.064100 j | dur=5.60 h | window ±2.0×dur -> ±0.0422 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=0.680934 j | dur=2.20 h | window ±2.0×dur -> ±0.2692 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=14.306780 j | dur=5.60 h | window ±2.0×dur -> ±0.0326 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=1.931449 j | dur=2.60 h | window ±2.0×dur -> ±0.1122 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=2.505239 j | dur=3.80 h | window ±2.0×dur -> ±0.1264 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=12.977151 j | dur=5.60 h | window ±2.0×dur -> ±0.0360 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=1.103653 j | dur=2.60 h | window ±2.0×dur -> ±0.1963 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=1.959818 j | dur=1.80 h | window ±2.0×dur -> ±0.0765 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=4.960776 j | dur=2.60 h | window ±2.0×dur -> ±0.0437 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=12.693654 j | dur=5.60 h | window ±2.0×dur -> ±0.0368 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=12.649085 j | dur=5.60 h | window ±2.0×dur -> ±0.0369 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=8.308329 j | dur=3.20 h | window ±2.0×dur -> ±0.0321 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=9.678886 j | dur=2.20 h | window ±2.0×dur -> ±0.0189 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=11.811363 j | dur=5.60 h | window ±2.0×dur -> ±0.0395 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=12.693654 j | dur=5.60 h | window ±2.0×dur -> ±0.0368 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=1.372920 j | dur=2.20 h | window ±2.0×dur -> ±0.1335 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=3.546492 j | dur=3.20 h | window ±2.0×dur -> ±0.0752 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=4.089128 j | dur=4.60 h | window ±2.0×dur -> ±0.0937 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=3.704777 j | dur=4.60 h | window ±2.0×dur -> ±0.1035 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=1.866987 j | dur=1.20 h | window ±2.0×dur -> ±0.0536 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=12.129506 j | dur=4.60 h | window ±2.0×dur -> ±0.0316 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=10.034759 j | dur=1.20 h | window ±2.0×dur -> ±0.0100 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=13.061843 j | dur=5.60 h | window ±2.0×dur -> ±0.0357 phase]\n",
      "[Multi-vues] Global: 2001 points | Folded: ok | Local: ok\n",
      "[P=3.779400 j | dur=2.60 h | window ±2.0×dur -> ±0.0573 phase]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5) Exemple d’utilisation (démonstration)\n",
    "# -----------------------------\n",
    "\n",
    "# (a) Colonne temps/flux\n",
    "time_col, flux_col = infer_time_flux_columns(df)\n",
    "\n",
    "# (b) Stub labels (remplacez par vos vrais labels {gid:0/1})\n",
    "#     -> On prend 50 groupes, on marque ~10% positifs juste pour tester\n",
    "labels_by_gid = {}\n",
    "for i, (gid, _sub) in enumerate(group_iter(df)):\n",
    "    labels_by_gid[gid] = 1 if (i % 10 == 0) else 0\n",
    "    if i >= 49: break\n",
    "\n",
    "# (c) Split train/val\n",
    "all_gids = list(labels_by_gid.keys())\n",
    "random.shuffle(all_gids)\n",
    "split = int(0.8 * len(all_gids))\n",
    "train_gids = set(all_gids[:split]); val_gids = set(all_gids[split:])\n",
    "\n",
    "train_labels = {gid: labels_by_gid[gid] for gid in train_gids}\n",
    "val_labels   = {gid: labels_by_gid[gid] for gid in val_gids}\n",
    "\n",
    "id_col = infer_id_column(df)\n",
    "\n",
    "id_col = infer_id_column(df)\n",
    "train_df = df[df[id_col].astype(str).isin({g.split(\"=\")[1] for g in train_gids})] if id_col else df\n",
    "val_df   = df[df[id_col].astype(str).isin({g.split(\"=\")[1] for g in val_gids})]   if id_col else df\n",
    "\n",
    "# (d) Datasets / Loaders\n",
    "\n",
    "bls_params = dict(\n",
    "    n_periods=5000,\n",
    "    min_period_hours=7.0,\n",
    "    max_period_frac_baseline=0.9,\n",
    "    durations_hours=(1.0, 12.0),\n",
    "    n_durations=10,\n",
    "    top_k=1\n",
    ")\n",
    "\n",
    "\n",
    "train_set = MultiViewDataset(train_df, cfg, time_col, flux_col, train_labels,\n",
    "                             run_bls=True, bls_params=bls_params, max_groups=None)\n",
    "val_set   = MultiViewDataset(val_df,   cfg, time_col, flux_col, val_labels,\n",
    "                             run_bls=True, bls_params=bls_params, max_groups=None)\n",
    "\n",
    "# (Optionnel mais recommandé) PRÉCHAUFFER le cache de val (une seule passe)\n",
    "# évite de recalculer BLS pendant la calibration/évaluation\n",
    "print(\"[Cache] warm-up validation …\")\n",
    "val_set.warm_cache()\n",
    "print(\"[Cache] warm-up done.\")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=4, shuffle=True, collate_fn=collate_mv, num_workers=0)\n",
    "val_loader   = DataLoader(val_set,   batch_size=4, shuffle=False, collate_fn=collate_mv, num_workers=0)\n",
    "\n",
    "print(f\"[Data] train groups={len(train_set)} | val groups={len(val_set)}\")\n",
    "\n",
    "# (e) Pré-entraînement auto-supervisé (2 époques rapides)\n",
    "pretrain_masked_reconstruction_fast(\n",
    "    model_mt, train_loader,\n",
    "    mask_frac=0.15,\n",
    "    n_epochs=1,                 # réduit\n",
    "    lr=3e-4,\n",
    "    crop_len=512,               # séquence << 2000\n",
    "    max_batches_per_epoch=40,   # borne le coût\n",
    "    amp=True                    # mixed precision\n",
    ")\n",
    "\n",
    "# (f) Fine-tuning supervisé avec Focal Loss + early stopping PR-AUC\n",
    "best_ap = train_supervised(model_mt, train_loader, val_loader,\n",
    "                           n_epochs=10, lr=3e-4,\n",
    "                           use_focal=True,                     # FocalLoss\n",
    "                           class_weight_neg=1.0, class_weight_pos=5.0,  # (ignoré si focal)\n",
    "                           early_stop_patience=3)\n",
    "\n",
    "print(f\"[Training] meilleur PR-AUC (val) = {best_ap:.4f}\")\n",
    "\n",
    "# (g) Dernier contrôle de métriques\n",
    "ap, rec95, (prec, rec, thr) = evaluate_pr_auc(model_mt, val_loader)\n",
    "print(f\"[Eval] PR-AUC(val)={ap:.4f} | R@P>=0.95={rec95:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garde-fou probabiliste & Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration des probabilités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Calibration des probabilités (Platt / Isotone) + métriques (Brier, ECE) + fiabilité\n",
    "# Hypothèses (mêmes variables) :\n",
    "#   - `model_mt` : modèle déjà entraîné (MultiViewTransformerPhysV2MT)\n",
    "#   - `val_loader` : DataLoader de validation (batch -> (batch_dict, y, gids))\n",
    "#   - Sortie brute : out[\"logit\"] et probas out[\"p_planet\"] = sigmoid(logit)\n",
    "# ==========================================================\n",
    "import numpy as np, torch, matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------- 1) Collecte des logits/probas sur validation ----------\n",
    "@torch.no_grad()\n",
    "def collect_val_scores(model, loader):\n",
    "    model.eval()\n",
    "    logits, probs, labels = [], [], []\n",
    "    use_amp = torch.cuda.is_available()\n",
    "    for batch, y, _ in loader:\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            out = model(batch, tabular=None)\n",
    "        logits.append(out[\"logit\"].detach().cpu().numpy())\n",
    "        probs.append(out[\"p_planet\"].detach().cpu().numpy())\n",
    "        labels.append(y.detach().cpu().numpy())\n",
    "    logits = np.concatenate(logits)\n",
    "    probs  = np.concatenate(probs)\n",
    "    labels = np.concatenate(labels).astype(int)\n",
    "    return logits, probs, labels\n",
    "\n",
    "logits_val, probs_val, y_val = collect_val_scores(model_mt, val_loader)\n",
    "\n",
    "# ---------- 2) Split \"calibration-fit\" / \"calibration-eval\" (50/50) ----------\n",
    "rng = np.random.RandomState(42)\n",
    "idx = np.arange(len(y_val))\n",
    "rng.shuffle(idx)\n",
    "mid = len(idx) // 2\n",
    "fit_idx, eval_idx = idx[:mid], idx[mid:]\n",
    "\n",
    "fit_logits, fit_probs, fit_y = logits_val[fit_idx], probs_val[fit_idx], y_val[fit_idx]\n",
    "eval_logits, eval_probs, eval_y = logits_val[eval_idx], probs_val[eval_idx], y_val[eval_idx]\n",
    "\n",
    "# ---------- 3) Platt scaling (régression logistique 1D sur logit) ----------\n",
    "platt = LogisticRegression(solver=\"lbfgs\")\n",
    "platt.fit(fit_logits.reshape(-1, 1), fit_y)\n",
    "\n",
    "def apply_platt(logits):\n",
    "    return platt.predict_proba(np.asarray(logits).reshape(-1,1))[:,1]\n",
    "\n",
    "# ---------- 4) Régression isotone (non-paramétrique) ----------\n",
    "# On entraîne l’isotone sur les PROBAS non calibrées (on pourrait aussi l'appliquer aux logits).\n",
    "iso = IsotonicRegression(y_min=0.0, y_max=1.0, out_of_bounds=\"clip\")\n",
    "iso.fit(fit_probs, fit_y.astype(float))\n",
    "\n",
    "def apply_isotonic(probs):\n",
    "    return iso.transform(np.asarray(probs))\n",
    "\n",
    "# ---------- 5) ECE (Expected Calibration Error) ----------\n",
    "def expected_calibration_error(y_true, p_pred, n_bins=15):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    p_pred = np.asarray(p_pred)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        m = (p_pred >= bins[i]) & (p_pred < bins[i+1])\n",
    "        if m.any():\n",
    "            conf = p_pred[m].mean()\n",
    "            acc  = y_true[m].mean()\n",
    "            ece += (m.mean()) * abs(acc - conf)\n",
    "    return ece\n",
    "\n",
    "# ---------- 6) Évaluation des calibrations ----------\n",
    "def eval_calibration(y, p_uncal, p_platt, p_iso, tag=\"Val\"):\n",
    "    out = {}\n",
    "    out[\"Brier_uncal\"] = brier_score_loss(y, p_uncal)\n",
    "    out[\"Brier_platt\"] = brier_score_loss(y, p_platt)\n",
    "    out[\"Brier_iso\"]   = brier_score_loss(y, p_iso)\n",
    "    out[\"ECE_uncal\"]   = expected_calibration_error(y, p_uncal)\n",
    "    out[\"ECE_platt\"]   = expected_calibration_error(y, p_platt)\n",
    "    out[\"ECE_iso\"]     = expected_calibration_error(y, p_iso)\n",
    "    print(f\"[{tag}] Brier  uncal={out['Brier_uncal']:.4f} | platt={out['Brier_platt']:.4f} | iso={out['Brier_iso']:.4f}\")\n",
    "    print(f\"[{tag}]  ECE   uncal={out['ECE_uncal']:.4f} | platt={out['ECE_platt']:.4f} | iso={out['ECE_iso']:.4f}\")\n",
    "    return out\n",
    "\n",
    "# Probas calibrées sur le split d’éval\n",
    "p_platt_eval = apply_platt(eval_logits)\n",
    "p_iso_eval   = apply_isotonic(eval_probs)\n",
    "\n",
    "metrics_eval = eval_calibration(eval_y, eval_probs, p_platt_eval, p_iso_eval, tag=\"Val-Eval\")\n",
    "\n",
    "# ---------- 7) Diagrammes de fiabilité ----------\n",
    "def reliability_diagram(y, p_list, labels, n_bins=15, title=\"Reliability Diagram\"):\n",
    "    bins = np.linspace(0,1,n_bins+1)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    # ligne parfaite\n",
    "    plt.plot([0,1],[0,1], \"--\", lw=1.5, label=\"Parfait\")\n",
    "    for p, lab in zip(p_list, labels):\n",
    "        accs, confs = [], []\n",
    "        for i in range(n_bins):\n",
    "            m = (p >= bins[i]) & (p < bins[i+1])\n",
    "            if m.any():\n",
    "                accs.append(y[m].mean())\n",
    "                confs.append(p[m].mean())\n",
    "        if len(confs):\n",
    "            plt.plot(confs, accs, marker=\"o\", lw=1.5, label=lab)\n",
    "    plt.xlabel(\"Confiance moyenne (bin)\")\n",
    "    plt.ylabel(\"Précision observée (bin)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.axis(\"square\")\n",
    "    plt.xlim(0,1); plt.ylim(0,1)\n",
    "    plt.show()\n",
    "\n",
    "reliability_diagram(\n",
    "    eval_y,\n",
    "    [eval_probs, p_platt_eval, p_iso_eval],\n",
    "    labels=[\"Non calibrée\",\"Platt\",\"Isotone\"],\n",
    "    n_bins=15,\n",
    "    title=\"Fiabilité — Validation (split d'éval)\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---------- 8) Utilisation pratique en inference ----------\n",
    "# Choisissez une des deux calibrations (souvent Isotone donne une ECE plus faible sur assez de données).\n",
    "# Exemple : wrapper qui renvoie des proba calibrées pour n’importe quel logit/proba du modèle.\n",
    "def calibrate_outputs(logits, probs, method=\"isotonic\"):\n",
    "    if method == \"platt\":\n",
    "        return apply_platt(logits)\n",
    "    elif method == \"isotonic\":\n",
    "        return apply_isotonic(probs)\n",
    "    else:\n",
    "        return probs  # pas de calibration\n",
    "\n",
    "# Exemple d’application sur TOUTE la validation (non splittée) :\n",
    "p_platt_full = apply_platt(logits_val)\n",
    "p_iso_full   = apply_isotonic(probs_val)\n",
    "_ = eval_calibration(y_val, probs_val, p_platt_full, p_iso_full, tag=\"Val-Full\")\n",
    "reliability_diagram(\n",
    "    y_val,\n",
    "    [probs_val, p_platt_full, p_iso_full],\n",
    "    labels=[\"Non calibrée\",\"Platt\",\"Isotone\"],\n",
    "    n_bins=15,\n",
    "    title=\"Fiabilité — Validation (full)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction conforme (ensembles prédictifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Prédiction Conforme (classification binaire) — ensembles prédictifs Γ(x)\n",
    "# Logique et variables inchangées: on part de `model_mt` et `val_loader`\n",
    "# Deux variantes:\n",
    "#   (A) Symétrique (distance à 0.5) — simple, intuitive\n",
    "#   (B) Mondrian (conditionnelle à la classe) — couverture plus stable\n",
    "# Usage: choisissez `variant=\"symmetric\"` ou `variant=\"mondrian\"`\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "@torch.no_grad()\n",
    "def _collect_scores(model, loader):\n",
    "    \"\"\"Récupère (probas, labels) sur un loader (pas d'entrainement).\"\"\"\n",
    "    model.eval()\n",
    "    P, Y = [], []\n",
    "    for batch, y, _ in loader:\n",
    "        out = model(batch, tabular=None)\n",
    "        P.append(out[\"p_planet\"].detach().cpu().numpy())  # proba de y=1 (planète)\n",
    "        Y.append(y.detach().cpu().numpy())\n",
    "    P = np.concatenate(P).astype(np.float64)  # shape (N,)\n",
    "    Y = np.concatenate(Y).astype(np.int64)    # shape (N,)\n",
    "    return P, Y\n",
    "\n",
    "# --- découpe calibration/test au sein de la validation (50/50) ---\n",
    "probs_val, y_val = _collect_scores(model_mt, val_loader)\n",
    "idx = np.arange(len(y_val))\n",
    "rng = np.random.RandomState(123)\n",
    "rng.shuffle(idx)\n",
    "mid = len(idx) // 2\n",
    "cal_idx, test_idx = idx[:mid], idx[mid:]\n",
    "p_cal, y_cal = probs_val[cal_idx], y_val[cal_idx]\n",
    "p_tst, y_tst = probs_val[test_idx], y_val[test_idx]\n",
    "\n",
    "# ==========================================================\n",
    "# (A) Variante SYMÉTRIQUE — score = 0.5 - |p - 0.5|\n",
    "#   - score ∈ [0, 0.5]; plus le score est grand, plus le modèle est incertain\n",
    "#   - règle: Γ(x) = {0,1} si s(x) ≥ q_α, sinon singleton {ŷ}, où ŷ = 1{p≥0.5}\n",
    "# Couverture marginale 1-α (split conformal), garantie sur fréquence d’erreurs d’abstention.\n",
    "# ==========================================================\n",
    "@dataclass\n",
    "class SymmetricConformal:\n",
    "    q_alpha: float = None  # quantile de calibration\n",
    "\n",
    "    def fit(self, p_cal, y_cal, alpha=0.1):\n",
    "        # scores d'incertitude\n",
    "        s = 0.5 - np.abs(p_cal - 0.5)\n",
    "        # quantile conforme (Vovk: ceil((n+1)*(1-alpha))/n) -> on prend quantile conservatif\n",
    "        n = len(s)\n",
    "        k = int(np.ceil((n + 1) * (1 - alpha))) - 1\n",
    "        k = np.clip(k, 0, n - 1)\n",
    "        self.q_alpha = np.sort(s)[k]\n",
    "        return self\n",
    "\n",
    "    def predict_set(self, p, alpha=None):\n",
    "        \"\"\"Retourne un ensemble {0}, {1} ou {0,1} par proba p (float).\"\"\"\n",
    "        if self.q_alpha is None:\n",
    "            raise RuntimeError(\"SymmetricConformal non entraîné. Appelez fit() d'abord.\")\n",
    "        s = 0.5 - np.abs(p - 0.5)\n",
    "        if s >= self.q_alpha:\n",
    "            return {0, 1}  # incertain -> abstention\n",
    "        return {1} if p >= 0.5 else {0}\n",
    "\n",
    "    def batch_predict_sets(self, p_arr):\n",
    "        return [self.predict_set(p) for p in p_arr]\n",
    "\n",
    "# ==========================================================\n",
    "# (B) Variante MONDRIAN (classe-conditionnelle)\n",
    "#   - scores pour la classe vraie: s_1 = 1 - p (si y=1), s_0 = p (si y=0)\n",
    "#   - on calibre deux quantiles séparés q1, q0\n",
    "#   - p-values conformes: p̂_1(x) = (#{i:y_i=1 & s_1i ≥ s_1(x)}+1)/(n1+1) ; idem pour 0\n",
    "#   - Γ(x) = { y ∈ {0,1} : p̂_y(x) > α }\n",
    "#   → meilleures garanties conditionnelles quand les classes sont très déséquilibrées\n",
    "# ==========================================================\n",
    "@dataclass\n",
    "class MondrianConformal:\n",
    "    s1_cal: np.ndarray = None  # scores de la classe 1 sur calibration\n",
    "    s0_cal: np.ndarray = None  # scores de la classe 0 sur calibration\n",
    "\n",
    "    def fit(self, p_cal, y_cal):\n",
    "        self.s1_cal = (1.0 - p_cal[y_cal == 1])  # grands si le modèle sous-estime les positifs\n",
    "        self.s0_cal = (p_cal[y_cal == 0])        # grands si le modèle sur-estime les positifs\n",
    "        return self\n",
    "\n",
    "    def _pvalue(self, s_cal, s_x):\n",
    "        # p-value conforme (inclut +1 au numérateur et dénominateur pour validité finie)\n",
    "        n = len(s_cal)\n",
    "        ge = np.sum(s_cal >= s_x)\n",
    "        return (ge + 1.0) / (n + 1.0)\n",
    "\n",
    "    def predict_set(self, p, alpha=0.1):\n",
    "        if self.s1_cal is None or self.s0_cal is None:\n",
    "            raise RuntimeError(\"MondrianConformal non entraîné. Appelez fit() d'abord.\")\n",
    "        s1 = 1.0 - p   # score si étiquette candidate = 1\n",
    "        s0 = p         # score si étiquette candidate = 0\n",
    "        pv1 = self._pvalue(self.s1_cal, s1)\n",
    "        pv0 = self._pvalue(self.s0_cal, s0)\n",
    "        S = set()\n",
    "        if pv1 > alpha: S.add(1)\n",
    "        if pv0 > alpha: S.add(0)\n",
    "        return S if len(S) > 0 else {0,1}  # (rare) fallback entièrement indéterminé\n",
    "\n",
    "    def batch_predict_sets(self, p_arr, alpha=0.1):\n",
    "        return [self.predict_set(p, alpha=alpha) for p in p_arr]\n",
    "\n",
    "# ==========================================================\n",
    "# Entraînement des calibrateurs + évaluation couverture et taille moyenne de Γ\n",
    "# ==========================================================\n",
    "alpha = 0.10  # cible: ≤10% des vrais labels en dehors de Γ\n",
    "\n",
    "sym_cp = SymmetricConformal().fit(p_cal, y_cal, alpha=alpha)\n",
    "mon_cp = MondrianConformal().fit(p_cal, y_cal)\n",
    "\n",
    "def _eval_conformal(p_tst, y_tst, cp, variant=\"symmetric\", alpha=alpha):\n",
    "    sets = cp.batch_predict_sets(p_tst) if variant==\"symmetric\" else cp.batch_predict_sets(p_tst, alpha=alpha)\n",
    "    # couverture: 1{y ∈ Γ(x)}\n",
    "    cover = np.mean([y in S for y, S in zip(y_tst, sets)])\n",
    "    # taux d'abstention: 1{ Γ(x) = {0,1} }\n",
    "    abst = np.mean([len(S) == 2 for S in sets])\n",
    "    # taille moyenne |Γ|\n",
    "    avg_size = np.mean([len(S) for S in sets])\n",
    "    return cover, abst, avg_size, sets\n",
    "\n",
    "cov_sym, abst_sym, size_sym, sets_sym = _eval_conformal(p_tst, y_tst, sym_cp, \"symmetric\", alpha=alpha)\n",
    "cov_mon, abst_mon, size_mon, sets_mon = _eval_conformal(p_tst, y_tst, mon_cp, \"mondrian\",  alpha=alpha)\n",
    "\n",
    "print(f\"[Conformal SYM]   α={alpha:.2f} | couverture={cov_sym:.3f} | abstention={abst_sym:.3f} | taille moyenne={size_sym:.2f}\")\n",
    "print(f\"[Conformal MON]   α={alpha:.2f} | couverture={cov_mon:.3f} | abstention={abst_mon:.3f} | taille moyenne={size_mon:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Utilisation en pratique (inférence)\n",
    "#   - vous avez un tableau de probas p_hat sur de nouveaux objets → renvoyer Γ(x)\n",
    "#   - choisissez la variante et α\n",
    "# ==========================================================\n",
    "def conformal_predict_sets(probs, method=\"mondrian\", alpha=0.1):\n",
    "    \"\"\"\n",
    "    probs: array-like de p_hat (proba 'planète')\n",
    "    Retourne: liste d'ensembles prédictifs {0}, {1}, {0,1}\n",
    "    \"\"\"\n",
    "    if method == \"symmetric\":\n",
    "        return SymmetricConformal(q_alpha=sym_cp.q_alpha).batch_predict_sets(np.asarray(probs))\n",
    "    else:\n",
    "        return MondrianConformal(s1_cal=mon_cp.s1_cal, s0_cal=mon_cp.s0_cal).batch_predict_sets(np.asarray(probs), alpha=alpha)\n",
    "\n",
    "# Exemple: appliquer aux probas du split test\n",
    "Gamma = conformal_predict_sets(p_tst, method=\"mondrian\", alpha=alpha)\n",
    "# Petit aperçu lisible (premiers 10)\n",
    "for i, (p, y, S) in enumerate(list(zip(p_tst[:10], y_tst[:10], Gamma[:10]))):\n",
    "    lab = {0: \"non-planète\", 1: \"planète\"}\n",
    "    print(f\"[ex{i:02d}] p̂={p:.3f} | y={lab[y]} | Γ(x)={{{', '.join(lab[z] for z in sorted(S))}}}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selective classification (rejet contrôlé)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seuil de décision optimisé (rappel maximal)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2894,
     "sourceId": 4877,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8390210,
     "sourceId": 13241378,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8397874,
     "sourceId": 13252810,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8401290,
     "sourceId": 13258044,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "cours",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
